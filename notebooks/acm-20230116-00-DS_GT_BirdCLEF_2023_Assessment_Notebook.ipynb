{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DS@GT BirdCLEF 2023 Asssessment Notebook\n",
    "\n",
    "[BirdCLEF](https://ceur-ws.org/Vol-3180/paper-154.pdf) is a classification and prediction competition that runs annually as part of the Conference and Labs of the Evaluation Forum (CLEF).\n",
    "The goal of the competition is to help classify soundscapes containing bird songs. \n",
    "\n",
    "This notebook tests familiarity with tools used in the project software stack for [BirdCLEF 2023](https://www.imageclef.org/BirdCLEF2023).\n",
    "The dataset is derived from the 2022 competition training dataset and features from the [BirdNET project](https://birdnet.cornell.edu/).\n",
    "You can use any library available to you, and reference external documentation.\n",
    "\n",
    "Make a copy of the notebook: `File > Save a copy in Drive`. \n",
    "When you are done with the notebook, share the results with acmiyaguchi@gatech.edu.\n",
    "\n",
    "Also see the [DS@GT Kaggle Competition Team proposal for the BirdCLEF 2023 team](https://docs.google.com/document/d/13Nq0RmNe714f2YCTXfG5BjuHRBc_3gBVd4ggzQ5d4MM/edit?usp=sharing).\n"
   ],
   "metadata": {
    "id": "ikIdyTsRxfKF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJM0aNjRxIHl"
   },
   "outputs": [],
   "source": [
    "# install necessary packages, and anything else you might want\n",
    "!pip install pyspark umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqMA4UXrxIHn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def get_spark(cores=4, memory=\"2g\"):\n",
    "    \"\"\"Get a spark session for a single driver.\"\"\"\n",
    "    os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "    os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "    return (\n",
    "        SparkSession.builder.config(\"spark.driver.memory\", memory)\n",
    "        .config(\"spark.driver.cores\", cores)\n",
    "        .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "\n",
    "\n",
    "# get the dataset for the assessment\n",
    "url = \"https://storage.googleapis.com/birdclef-2023/data/processed/2022-01-15-assessment.parquet\"\n",
    "df = pd.read_parquet(url)\n",
    "display(df.head())\n",
    "\n",
    "# get a spark context and create a dataframe for it\n",
    "spark = get_spark()\n",
    "spark_df = spark.createDataFrame(df)\n",
    "spark_df.printSchema()\n",
    "spark_df.show(n=1, vertical=True, truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. embeddings\n",
    "\n",
    "An embedding maps vectors in $\\mathbb{R}^n$ to $\\mathbb{R}^m$ such that distances (e.g., $L_1$ or $L_2$ norm) are preserved.\n",
    "In this question, we examine embeddings generated by passing training birdcall audio through [BirdNET-Analyzer](https://github.com/kahst/BirdNET-Analyzer).\n",
    "This model accepts audio at a 48kHz sampling rate in 3-second clips, extracts a spectrogram, and applies a deep convolutional neural network to classify the type of call in the clip. We can extract the second to last layer as an embedding (i.e., $\\mathbb{R}^{320}$ vector). See the [paper](https://www.sciencedirect.com/science/article/pii/S1574954121000273) for more details.\n",
    "\n",
    "For this notebook, we keep one embedding per audio track representing the most confident prediction of the audio. We select the three most common species in the dataset for analysis: [skylar], [normoc], and [houspa].\n",
    "\n",
    "[skylar]: https://ebird.org/species/skylar\n",
    "[normoc]: https://ebird.org/species/normoc\n",
    "[houspa]: https://ebird.org/species/houspa"
   ],
   "metadata": {
    "id": "LD7CgknK7ArT"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-czCDmgxIHq"
   },
   "source": [
    "### (a) Plot the BirdNET embeddings in a 2D or 3D scatterplot colored by `primary_label`.\n",
    "\n",
    "Hint: Use PCA or UMAP for dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPNTjYdcxIHq"
   },
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = np.stack(df.emb)\n",
    "primary_label = df.primary_label\n",
    "birdnet_label = df.birdnet_label\n",
    "\n",
    "# TODO: build plot that differentiates betweens different species"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (b) Describe the geometry of 1D embeddings and how you might use it to visualize data.\n",
    "\n",
    "No code is required for the question; a short answer will suffice."
   ],
   "metadata": {
    "id": "N2SFgp2a6NnX"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. k-nn classification\n",
    "\n",
    "A [K-Nearest Neighbor (K-NN) Classifier](https://scikit-learn.org/stable/modules/neighbors.html#classification) uses a majority vote of neighbors to assign a label to a point.\n",
    "We are interested in using K-NN classification as an semi-unsupervised labeling method on unlabeled training data.\n",
    "\n",
    "In this question, we will implement and analyze a K-NN classifier implemented in SQL (or PySpark Dataframes).\n",
    "We test familarity with SQL concepts, such as `GROUP BY`, `JOIN`, and `WINDOW` functions."
   ],
   "metadata": {
    "id": "ErnTyENj67p5"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-yGLHWlxIHs"
   },
   "source": [
    "\n",
    "### (a) How would you compute the nearest neighbors of all points in the BirdNET embedding dataset?\n",
    "\n",
    "Re-stated: for all vectors in $\\mathbb{R}^{n}$, how would you compute the $k$ closest neighbors for each vector.\n",
    "\n",
    "What distance metric would you use? What algorithms or libraries would you use?  What if the dataset does not fit into main memory? No code is required for the question; a short answer will suffice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zHULopqxIHs"
   },
   "source": [
    "### (b) What percentage of primary labels are correctly predicted by BirdNET for each species?\n",
    "\n",
    "You are given a table named `labels` defined by the following schema:\n",
    "\n",
    "name | type | description\n",
    "-|-|-\n",
    "id | integer | A unique identifier for a given audio clip\n",
    "primary_label | string | The species label assigned to the clip in the training dataset\n",
    "birdnet_label | string | The species label assigned by BirdNET Analyzer\n",
    "\n",
    "Compute how often the BirdNET analyzer matches the assigned training dataset label.\n",
    "\n",
    "---\n",
    "\n",
    "For this question, you **must** answer using PySpark SQL (a mostly-compliant ANSI SQL dialect) or the PySpark Dataframe API.\n",
    "See the [Spark SQL reference](https://spark.apache.org/docs/3.2.0/sql-ref.html) and [API docs](https://spark.apache.org/docs/3.1.2/api/python/reference/pyspark.sql.html) for more information.\n",
    "\n",
    "Hint: common table expressions (CTEs) are useful for organizing queries, and for reusing subqueries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JCipUGFxIHt"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, Window\n",
    "\n",
    "labels = spark_df.select(\"id\", \"primary_label\", \"birdnet_label\")\n",
    "labels.createOrReplaceTempView(\"labels\")\n",
    "labels.printSchema()\n",
    "\n",
    "# NOTE: example of using the sql interface to spark\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "      SELECT\n",
    "          primary_label,\n",
    "          count(*) as n\n",
    "      FROM labels\n",
    "      GROUP BY 1\n",
    "      ORDER BY n DESC\n",
    "    \"\"\"\n",
    ").show()\n",
    "\n",
    "# NOTE: the same query, but using the dataframe interface\n",
    "labels.groupBy(\"primary_label\").agg(F.count(\"*\").alias(\"n\")).orderBy(F.desc(\"n\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TKZ08_LxIHt"
   },
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "      -- TODO: implement\n",
    "      select null;\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NORZRhg1xIHu"
   },
   "source": [
    "### (c) Compute labels for each point in the dataset using k-nn classification.\n",
    "\n",
    "For each id, find the most common label among its neighbors using the mode of the BirdNET labels.\n",
    "Run the `compute_pct` function to compute the percentage of matching predictions.\n",
    "How does this answer compare to the answer in (b)?\n",
    "\n",
    "---\n",
    "\n",
    "For this question, you **must** answer using PySpark SQL (a mostly-compliant ANSI SQL dialect) or the PySpark Dataframe API.\n",
    "See the [Spark SQL reference](https://spark.apache.org/docs/3.2.0/sql-ref.html) and [API docs](https://spark.apache.org/docs/3.1.2/api/python/reference/pyspark.sql.html) for more information.\n",
    "\n",
    "Hint: Use a window function to assign a row number or rank based on counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HsbwHVfxIHu"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, Window\n",
    "\n",
    "neighbors = spark_df.select(\n",
    "    \"id\", F.posexplode(\"neighbors\").alias(\"pos\", \"neighbor_id\")\n",
    ").orderBy(\"id\", \"pos\")\n",
    "neighbors.createOrReplaceTempView(\"neighbors\")\n",
    "neighbors.printSchema()\n",
    "\n",
    "# NOTE: example of using the neighbors table with the labels table\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "      SELECT\n",
    "          neighbors.id,\n",
    "          pos,\n",
    "          neighbor_id,\n",
    "          primary_label\n",
    "      FROM neighbors\n",
    "      JOIN labels ON neighbors.neighbor_id = labels.id\n",
    "      LIMIT 5\n",
    "  \"\"\"\n",
    ").show()\n",
    "\n",
    "# NOTE: example of using the neighbors table with the labels table\n",
    "neighbors.join(labels.withColumnRenamed(\"id\", \"neighbor_id\"), on=\"neighbor_id\").select(\n",
    "    \"id\", \"pos\", \"neighbor_id\", \"primary_label\"\n",
    ").limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0CIVGnxxIHv"
   },
   "outputs": [],
   "source": [
    "knn_result = spark.sql(\n",
    "    \"\"\"\n",
    "      -- TODO: implement\n",
    "      SELECT\n",
    "        id,\n",
    "        'N/A' as birdnet_label\n",
    "      FROM labels\n",
    "      GROUP BY 1\n",
    "    \"\"\"\n",
    ")\n",
    "assert knn_result.columns == [\"id\", \"birdnet_label\"], \"mismatched columns\"\n",
    "assert knn_result.count() == labels.count(), \"mismatched row counts\"\n",
    "knn_result.groupBy(\"birdnet_label\").count().orderBy(F.desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CF2JtCOqxIHw"
   },
   "outputs": [],
   "source": [
    "# NOTE: to avoid spoiling the answer to part (b), we compute percentages in python/pandas\n",
    "def compute_pct(knn_result, labels):\n",
    "    temp_knn_df = knn_result.toPandas()\n",
    "    temp_labels_df = labels.select(\"id\", \"primary_label\").toPandas()\n",
    "\n",
    "    joined = temp_knn_df.merge(temp_labels_df, on=\"id\")\n",
    "\n",
    "    counts = {}\n",
    "    for label in temp_labels_df.primary_label.unique():\n",
    "        sub = joined[joined.primary_label == label]\n",
    "        a = sub[sub.birdnet_label == label].shape[0]\n",
    "        b = sub.shape[0]\n",
    "        counts[label] = a / b * 100\n",
    "\n",
    "    spark.createDataFrame(\n",
    "        [(k, float(v)) for k, v in counts.items()], [\"label\", \"pct\"]\n",
    "    ).orderBy(F.desc(\"pct\")).show()\n",
    "\n",
    "\n",
    "compute_pct(knn_result, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v86qRUhaxIHw"
   },
   "source": [
    "## 3. transfer learning\n",
    "\n",
    "[Transfer learning](https://en.wikipedia.org/wiki/Transfer_learning) is a problem that involves transfering knowledge from one problem domain to another.\n",
    "Advancements in large language model (LLM) embeddings on image generation like [CLIP](https://openai.com/blog/clip/) and [Stable Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion) can be considered a type of transfer learning.\n",
    "\n",
    "We are interested in reusing/fine-tuning the embedding layer of the BirdNET Analyzer on a more specific task in the upcoming BirdCLEF 2023 competition.\n",
    "In this question, we explore the use of embeddings in a simple classification task.\n",
    "We also test some familiarity with tools like [PyTorch](https://pytorch.org/).\n",
    "\n",
    "We create a binary classification task, which involves predicting whether an audio clip is `normoc` or not.\n",
    "We also limit our dataset to clips that are labeled `normoc` or `skylar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NelrY-cIxIHw"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "subset = df[df.primary_label.isin([\"normoc\", \"skylar\"])]\n",
    "X = np.stack(subset.emb)\n",
    "y = subset.primary_label.eq(\"normoc\").astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2FLn87uxIHw"
   },
   "source": [
    "### (a) Fit BirdNET embeddings to a logistic regression model\n",
    "\n",
    "Report the test accuracy of a model using `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: implement"
   ],
   "metadata": {
    "id": "BdbyNPZ1WgE4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1ZlXIGaxIHx"
   },
   "source": [
    "### (b) Fit BirdNET embeddings to a neural network\n",
    "\n",
    "Implement `Net` using a neural network with at least two layers. \n",
    "Use `train_generator` to fit the embedding and label data to the model.\n",
    "Plot the loss curve of the training procedure.\n",
    "Finally, report the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ea7tMyZxIHx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim=320):\n",
    "        super().__init__()\n",
    "        # NOTE: define layers in the initialization function\n",
    "        # self.layer1 = ...\n",
    "        # self.layer2 = ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "def train_generator(\n",
    "    net: Net,\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    epochs: int = 100,\n",
    "    criterion=nn.BCELoss(),\n",
    "    lr: float = 0.001,\n",
    "):\n",
    "    \"\"\"A python generator that yields the epoch and loss at each step.\"\"\"\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(torch.from_numpy(X_train).float())\n",
    "        loss = criterion(\n",
    "            outputs, torch.from_numpy(y_train.values.reshape(-1, 1)).float()\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        yield epoch, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eo67VIAdxIHy"
   },
   "outputs": [],
   "source": [
    "net = Net(input_dim=X_train.shape[1])\n",
    "# TODO: train the model\n",
    "# TODO: plot the loss curve\n",
    "# TODO: report accuracy score on the tests set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uezmXeBxIHy"
   },
   "source": [
    "### (c) Analyze the input data in the embedding space of the second-to-last layer of the model defined in part (b)\n",
    "\n",
    "We are interested in analyzing properties of the second-to-last layer of our neural network.\n",
    "Register a callback on a `torch` layer to capture activations on forward passes of model inference/training.\n",
    "Report the shape of the extracted activations on `X`.\n",
    "\n",
    "Perform some analysis on the extracted activations.\n",
    "Some examples:\n",
    "\n",
    "- Visualizing the embedding space labeled by `y`\n",
    "- Reporting the accuracy of a classifier on `y` using activations as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPDvs0XsxIHy"
   },
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/how-can-l-load-my-best-model-as-a-feature-extractor-evaluator/17254/6\n",
    "activations = {}\n",
    "\n",
    "\n",
    "def get_activation(name):\n",
    "    \"\"\"Register a hook to extract activations from a layer.\n",
    "\n",
    "    If we have three layers defined layer1, layer2, and layer3 in our network,\n",
    "    we would register the activations as follows:\n",
    "\n",
    "      >>> net.layer2.register_forward_hook(get_activations(\"layer2\"))\n",
    "\n",
    "    Then, activations will be available on every call to `forward`. State is\n",
    "    global, so it is overwritten on every call.\n",
    "\n",
    "    >>> net(X)\n",
    "    >>> activations[\"layer2\"]\n",
    "    \"\"\"\n",
    "\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach().numpy()\n",
    "\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: register the second to last layer\n",
    "\n",
    "# TODO: activate the layer and report the shape\n",
    "_ = net(torch.from_numpy(X).float())\n",
    "emb = activations.get(\"my-layer\")\n",
    "assert emb is not None, \"activation is missing\"\n",
    "\n",
    "# TODO: analyze (or visualize) the activations"
   ],
   "metadata": {
    "id": "aqaaj1up3_A1"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c0b2694cc72a4b1216248dce15f12c6ef2d809641a13c5c2db85cd65e60fdec"
   }
  },
  "colab": {
   "provenance": [],
   "toc_visible": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
