{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding ideas\n",
    "\n",
    "This notebook has some code to get started, and some ideas on how to achieve the following goals:\n",
    "\n",
    "- Building a KNN classifer\n",
    "- Annotating each track\n",
    "\n",
    "## setup\n",
    "\n",
    "### downloading the dataset\n",
    "\n",
    "Make sure that you have the dataset downloaded locally.\n",
    "At the root of the project, run this command:\n",
    "\n",
    "```bash\n",
    "gsutil -m rsync \\\n",
    "    gs://birdclef-2023/data/processed/birdclef-2023/train_embeddings/consolidated_v3_pre1/ \\\n",
    "    data/processed/birdclef-2023/train_embeddings/consolidated_v3_pre1/ \n",
    "```\n",
    "\n",
    "### using spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/14 23:26:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from birdclef.utils import get_spark\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# modify cores and memory as needed\n",
    "spark = get_spark(cores=8, memory=\"16g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- species: string (nullable = true)\n",
      " |-- track_stem: string (nullable = true)\n",
      " |-- track_type: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- embedding: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- prediction_vec: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- predictions: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- rank: long (nullable = true)\n",
      " |    |    |-- index: long (nullable = true)\n",
      " |    |    |-- label: string (nullable = true)\n",
      " |    |    |-- mapped_label: string (nullable = true)\n",
      " |    |    |-- probability: double (nullable = true)\n",
      " |-- start_time: long (nullable = true)\n",
      " |-- energy: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1198860"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/processed/birdclef-2023/train_embeddings/consolidated_v3/\"\n",
    "df = spark.read.parquet(path)\n",
    "df.printSchema()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------------------------------------------------------\n",
      " species        | wlwwar                                                                           \n",
      " track_stem     | XC475384_part003                                                                 \n",
      " track_type     | original                                                                         \n",
      " track_name     | wlwwar/XC475384_part003.mp3                                                      \n",
      " embedding      | [0.6336879134178162, 0.699510395526886, 0.43676260113716125, 1.18983256816864... \n",
      " prediction_vec | [-10.213504791259766, -9.510478973388672, -12.938481330871582, -9.79550075531... \n",
      " predictions    | [{0, 2005, Nucifraga caryocatactes_Eurasian Nutcracker, eurnut1, 0.0690114870... \n",
      " start_time     | 18                                                                               \n",
      " energy         | 1.2206932306289673                                                               \n",
      "-RECORD 1------------------------------------------------------------------------------------------\n",
      " species        | grecor                                                                           \n",
      " track_stem     | XC629875_part015                                                                 \n",
      " track_type     | source1                                                                          \n",
      " track_name     | grecor/XC629875_part015_source1.mp3                                              \n",
      " embedding      | [0.4763871431350708, 0.8781195282936096, 0.6997694969177246, 0.97224330902099... \n",
      " prediction_vec | [-8.629256248474121, -8.008709907531738, -10.350841522216797, -11.35367202758... \n",
      " predictions    | [{0, 291, Atlanticus testaceus_Protean Shieldback, t-11844441, 0.010979887098... \n",
      " start_time     | 60                                                                               \n",
      " energy         | 0.02938658744096756                                                              \n",
      "-RECORD 2------------------------------------------------------------------------------------------\n",
      " species        | grecor                                                                           \n",
      " track_stem     | XC629875_part006                                                                 \n",
      " track_type     | source3                                                                          \n",
      " track_name     | grecor/XC629875_part006_source3.mp3                                              \n",
      " embedding      | [1.277891755104065, 2.446718454360962, 0.7948735356330872, 0.8446668982505798... \n",
      " prediction_vec | [-13.74133586883545, -14.372939109802246, -13.05613899230957, -10.80665588378... \n",
      " predictions    | [{0, 1079, Egretta tricolor_Tricolored Heron, triher, 0.5416293740272522}, {1... \n",
      " start_time     | 87                                                                               \n",
      " energy         | 1.1638777256011963                                                               \n",
      "-RECORD 3------------------------------------------------------------------------------------------\n",
      " species        | wlwwar                                                                           \n",
      " track_stem     | XC475384_part000                                                                 \n",
      " track_type     | source0                                                                          \n",
      " track_name     | wlwwar/XC475384_part000_source0.mp3                                              \n",
      " embedding      | [1.042157530784607, 0.980938732624054, 0.26936259865760803, 2.047674894332885... \n",
      " prediction_vec | [-14.561668395996094, -15.171517372131348, -13.448974609375, -12.831357002258... \n",
      " predictions    | [{0, 2343, Phylloscopus trochilus_Willow Warbler, wlwwar, 0.9938302636146545}... \n",
      " start_time     | 51                                                                               \n",
      " energy         | 14.041417121887207                                                               \n",
      "-RECORD 4------------------------------------------------------------------------------------------\n",
      " species        | grecor                                                                           \n",
      " track_stem     | XC629875_part004                                                                 \n",
      " track_type     | source3                                                                          \n",
      " track_name     | grecor/XC629875_part004_source3.mp3                                              \n",
      " embedding      | [1.4064692258834839, 1.3224740028381348, 0.6532403230667114, 0.08462373167276... \n",
      " prediction_vec | [-15.395846366882324, -13.203960418701172, -11.997428894042969, -14.028895378... \n",
      " predictions    | [{0, 824, Corvus monedula_Eurasian Jackdaw, eurjac, 0.798206627368927}, {1, 2... \n",
      " start_time     | 15                                                                               \n",
      " energy         | 10.609950065612793                                                               \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, vertical=True, truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "|species|      track_stem|track_type|          track_name|           embedding|      prediction_vec|         predictions|start_time|              energy|\n",
      "+-------+----------------+----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "| wlwwar|XC475384_part003|  original|wlwwar/XC475384_p...|[0.63368791341781...|[-10.213504791259...|[{0, 2005, Nucifr...|        18|  1.2206932306289673|\n",
      "| grecor|XC629875_part015|   source1|grecor/XC629875_p...|[0.47638714313507...|[-8.6292562484741...|[{0, 291, Atlanti...|        60| 0.02938658744096756|\n",
      "| grecor|XC629875_part006|   source3|grecor/XC629875_p...|[1.27789175510406...|[-13.741335868835...|[{0, 1079, Egrett...|        87|  1.1638777256011963|\n",
      "| wlwwar|XC475384_part000|   source0|wlwwar/XC475384_p...|[1.04215753078460...|[-14.561668395996...|[{0, 2343, Phyllo...|        51|  14.041417121887207|\n",
      "| grecor|XC629875_part004|   source3|grecor/XC629875_p...|[1.40646922588348...|[-15.395846366882...|[{0, 824, Corvus ...|        15|  10.609950065612793|\n",
      "| grecor|XC629875_part013|   source0|grecor/XC629875_p...|[1.52420341968536...|[-12.121448516845...|[{0, 218, Aplonis...|        96| 0.15435950458049774|\n",
      "| grecor|XC629875_part009|   source3|grecor/XC629875_p...|[1.47978460788726...|[-13.287464141845...|[{0, 2352, Pica p...|        60|   3.351954698562622|\n",
      "| wlwwar|XC475384_part003|   source2|wlwwar/XC475384_p...|[0.92958122491836...|[-11.373017311096...|[{0, 980, Dendroc...|        66|  1.0065091848373413|\n",
      "| wlwwar|XC475384_part007|   source1|wlwwar/XC475384_p...|[0.46993312239646...|[-7.6409249305725...|[{0, 1437, Hippol...|        21|0.016603998839855194|\n",
      "| grecor|XC629875_part012|   source0|grecor/XC629875_p...|[1.10040688514709...|[-14.156658172607...|[{0, 2935, Sturnu...|       117|  1.4235236644744873|\n",
      "| wlwwar|XC475384_part000|  original|wlwwar/XC475384_p...|[1.20464932918548...|[-10.123322486877...|[{0, 2356, Picoid...|         9|  1.9960569143295288|\n",
      "| grecor|XC629875_part015|   source3|grecor/XC629875_p...|[1.52604115009307...|[-15.098612785339...|[{0, 824, Corvus ...|        21|  13.791864395141602|\n",
      "| grecor|XC629875_part010|   source2|grecor/XC629875_p...|[1.09770095348358...|[-10.553102493286...|[{0, 2077, Oriolu...|        84|   4.027913570404053|\n",
      "| grecor|XC629875_part007|   source3|grecor/XC629875_p...|[1.03657412528991...|[-17.432664871215...|[{0, 163, Anser a...|        51|     65.850830078125|\n",
      "| grecor|XC629875_part015|   source3|grecor/XC629875_p...|[1.10262870788574...|[-11.859588623046...|[{0, 2352, Pica p...|        78| 0.03858273848891258|\n",
      "| wlwwar|XC475384_part002|   source0|wlwwar/XC475384_p...|[0.85798233747482...|[-15.649844169616...|[{0, 2343, Phyllo...|       108|  12.837133407592773|\n",
      "| wlwwar|XC475384_part000|   source3|wlwwar/XC475384_p...|[1.07169687747955...|[-7.3436188697814...|[{0, 1151, Erporn...|        48|0.003633054438978...|\n",
      "| grecor|XC629875_part007|   source2|grecor/XC629875_p...|[0.49804612994194...|[-10.932131767272...|[{0, 1022, Dog_Do...|        93|  1.9762864112854004|\n",
      "| grecor|XC629875_part011|   source3|grecor/XC629875_p...|[1.24460518360137...|[-13.444816589355...|[{0, 801, Coracia...|       147|    6.52481746673584|\n",
      "| wlwwar|XC475384_part004|   source1|wlwwar/XC475384_p...|[0.66851824522018...|[-8.4985179901123...|[{0, 2364, Picus ...|        27|0.015501908957958221|\n",
      "+-------+----------------+----------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"species\").count().orderBy(F.desc(\"count\")).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a sample of tracks that will make things easier to work with\n",
    "\n",
    "sample = df.where(\"species in ('woosan', 'blakit1', 'rbsrob1')\").cache()\n",
    "sample.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot of embeddings of high confidence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window, functions as F\n",
    "\n",
    "# keep the track_type for each\n",
    "highest_energy_channel = (\n",
    "    sample\n",
    "    # get the track stem without the part\n",
    "    .withColumn(\"original_track_stem\", F.split(F.col(\"track_stem\"), \"_\").getItem(0))\n",
    "    .where(\"track_type != 'original'\")\n",
    "    # get the track type that has the most energy\n",
    "    .withColumn(\n",
    "        \"rank\",\n",
    "        F.rank().over(\n",
    "            Window.partitionBy(\"original_track_stem\").orderBy(F.desc(\"energy\"))\n",
    "        ),\n",
    "    )\n",
    "    # keep the first row\n",
    "    .where(F.col(\"rank\") == 1)\n",
    "    # drop the rank column\n",
    "    .select(\"species\", \"track_stem\", \"track_type\")\n",
    "    .distinct()\n",
    ")\n",
    "\n",
    "highest_energy_channel.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the highest predictions by exploding the values\n",
    "\n",
    "exploded_embeddings = (\n",
    "    sample\n",
    "    # join against the highest energy channel\n",
    "    .join(\n",
    "        highest_energy_channel,\n",
    "        on=[\"species\", \"track_stem\", \"track_type\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    # explode the embeddings, these are ordered by confidence\n",
    "    .withColumn(\"predictions\", F.explode(\"predictions\")).select(\n",
    "        \"species\",\n",
    "        \"track_stem\",\n",
    "        \"track_type\",\n",
    "        \"start_time\",\n",
    "        \"track_name\",\n",
    "        \"embedding\",\n",
    "        \"predictions.*\",\n",
    "    )\n",
    "    # simplifying assumption: we assume the prediction with the highest confidence is the true label\n",
    "    .where(\"rank = 0 and probability > 0.5\")\n",
    ")\n",
    "\n",
    "exploded_embeddings.drop(\"embedding\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of clips that have a prediction of any kind\n",
    "positive = exploded_embeddings.count()\n",
    "total = sample.count()\n",
    "positive / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = exploded_embeddings.select(\n",
    "    \"species\", \"probability\", \"embedding\"\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# get the embeddings\n",
    "X = np.stack(predictions.embedding.values)\n",
    "\n",
    "# get the species\n",
    "species = predictions.species.values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(species)\n",
    "\n",
    "# fit the umap model\n",
    "umap = UMAP(n_components=2)\n",
    "X_umap = umap.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "plt.scatter(X_umap[:, 0], X_umap[:, 1], c=y, s=10, alpha=0.1)\n",
    "# add dummy plot with label for each species\n",
    "for i, species in enumerate(le.classes_):\n",
    "    plt.scatter([], [], label=species)\n",
    "plt.legend()\n",
    "plt.title(\"UMAP of blakit1, rbsrob, and woosan\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to find the most representative points of each of these species, we could compute the K-means of each species.\n",
    "We would also want to take care to find all of the points are noisy (human voices, machines, dogs, footsteps, environmental, etc) and create a separate no-call class for them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labels from prediction logits\n",
    "\n",
    "Instead of using the predictions struct, we can derive probabilities from the raw prediction logits.\n",
    "This could be useful if we're looking to analyze a specific class across all the tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdclef import birdnet\n",
    "\n",
    "# labels = birdnet.load_labels(\"../vendor/BirdNET-Analyzer\")\n",
    "# mapped_labels = birdnet.load_mapped_labels(\"../vendor/BirdNET-Analyzer\")\n",
    "\n",
    "labels = birdnet.load_labels(\"../data/models/birdnet-analyzer-pruned\")\n",
    "mapped_labels = birdnet.load_mapped_labels(\"../data/models/birdnet-analyzer-pruned\")\n",
    "list(zip(labels, mapped_labels))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label with human voice\n",
    "[(i, x) for i, x in enumerate(labels) if \"human\" in x.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = spark.createDataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"label\": label,\n",
    "            \"mapped_label\": mapped_label,\n",
    "            \"index\": i,\n",
    "        }\n",
    "        for i, (label, mapped_label) in enumerate(zip(labels, mapped_labels))\n",
    "    ]\n",
    ")\n",
    "label_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_vocals = (\n",
    "    sample\n",
    "    # explode the predictions with their indices\n",
    "    .select(\n",
    "        \"species\",\n",
    "        \"track_name\",\n",
    "        \"start_time\",\n",
    "        F.posexplode(\"prediction_vec\").alias(\"index\", \"logit\"),\n",
    "    )\n",
    "    # join with the labels, in case we want to use it for anything\n",
    "    .join(label_df, on=\"index\", how=\"inner\")\n",
    "    # now only keep human vocals\n",
    "    .where(\"index = 1450\")\n",
    "    # and convert the logit to a probability via sigmoid\n",
    "    .withColumn(\"probability\", F.expr(\"1/(1+exp(-logit))\"))\n",
    ").toPandas()\n",
    "\n",
    "human_vocals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(human_vocals.probability).hist(bins=100)\n",
    "plt.title(\"log probability of human vocals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_vocals[human_vocals.probability > 0.2].sort_values(\"probability\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's listen to the audio\n",
    "# import IPython.display as ipd\n",
    "\n",
    "# train_embeddings_path = (\n",
    "#     \"../data/processed/birdclef-2023/train_embeddings/consolidated_v3\"\n",
    "# )\n",
    "# track_name = \"rbsrob1/XC393114_source2.mp3\"\n",
    "# ipd.Audio(f\"{train_embeddings_path}/audio/{track_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can hear very muffled human voices in this track."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## track annotation\n",
    "\n",
    "The code here is similar; we also need a classifier to reasonably annotate the other channels.\n",
    "However, the output schema is good enough to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_cols = [\"species\", \"track_name\", \"start_time\"]\n",
    "annotation = (\n",
    "    sample.select(*join_cols)\n",
    "    .join(\n",
    "        # We add a column with our \"prediction\", which could can be from a more\n",
    "        # sophisticated model. Here, we're just using the simplifying assumption\n",
    "        # that the most confident prediction of the highest energy channel\n",
    "        # matches the species of the track.\n",
    "        exploded_embeddings.select(*join_cols).withColumn(\"label\", F.col(\"species\")),\n",
    "        on=join_cols,\n",
    "        how=\"outer\",\n",
    "    )\n",
    "    .fillna(\"none\")\n",
    "    .orderBy(\"species\", \"track_name\", \"start_time\")\n",
    ")\n",
    "\n",
    "# TODO: note how only the track name for the source above has labels. This needs\n",
    "# to be handled so every track has a label. This is probably best left until\n",
    "# there's a proper model for predictions.\n",
    "annotation.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add dataset with baseline model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# Load model from pickle file\n",
    "model_path = Path(\"../data/models/baseline/logistic_full.pkl\")\n",
    "clf = pickle.loads(model_path.read_bytes())\n",
    "print(clf.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, FloatType, StructType, StructField\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def predict_udf(vector):\n",
    "    # Convert the list of features to a numpy array and reshape it to a 2D array\n",
    "    embedding_array = np.array(vector).reshape(1, -1)\n",
    "    # Apply the model to get predictions\n",
    "    preds = str(clf.predict(embedding_array)[0])\n",
    "    # Get the probability of the predicted class\n",
    "    proba = float(clf.predict_proba(embedding_array).max())\n",
    "    return preds, proba\n",
    "\n",
    "\n",
    "# Define the schema of the output\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"prediction\", StringType(), nullable=True),\n",
    "        StructField(\"probability\", FloatType(), nullable=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the UDF with the specified schema\n",
    "predict_proba = udf(predict_udf, schema)\n",
    "\n",
    "\n",
    "# df is the consolidated_v3 dataset\n",
    "# model is the unpickled model\n",
    "df_with_preds_proba = df.withColumn(\"prediction_proba\", predict_proba(df[\"embedding\"]))\n",
    "\n",
    "# Results\n",
    "res = df_with_preds_proba.select(\n",
    "    \"track_name\",\n",
    "    \"start_time\",\n",
    "    \"prediction_proba.prediction\",\n",
    "    \"prediction_proba.probability\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write out res to a parquet file, using 1 or 2 partitions.\n",
    "# Use the processed/birdnet-2023 folder and make a new dataset under there.\n",
    "res.repartition(2).write.mode(\"overwrite\").parquet(\n",
    "    \"../data/processed/birdnet-2023/consolidated_v3_with_preds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+-----------+\n",
      "|          track_name|start_time|prediction|probability|\n",
      "+--------------------+----------+----------+-----------+\n",
      "|wlwwar/XC475384_p...|        18|   thrnig1|  0.5938948|\n",
      "|grecor/XC629875_p...|        60|   combuz1|  0.2286156|\n",
      "|grecor/XC629875_p...|        87|    litegr|  0.8291227|\n",
      "|wlwwar/XC475384_p...|        51|    wlwwar| 0.99999917|\n",
      "|grecor/XC629875_p...|        15|    strher|  0.3981949|\n",
      "|grecor/XC629875_p...|        96|   fotdro5|  0.2228314|\n",
      "|grecor/XC629875_p...|        60|   combuz1|   0.570118|\n",
      "|wlwwar/XC475384_p...|        66|    wlwwar|  0.6390262|\n",
      "|wlwwar/XC475384_p...|        21|   combuz1| 0.32505578|\n",
      "|grecor/XC629875_p...|       117|   combuz1|  0.5007306|\n",
      "|wlwwar/XC475384_p...|         9|   thrnig1|  0.7924493|\n",
      "|grecor/XC629875_p...|        21|    egygoo| 0.50189364|\n",
      "|grecor/XC629875_p...|        84|   thrnig1|  0.4570964|\n",
      "|grecor/XC629875_p...|        51|    greegr| 0.87462825|\n",
      "|grecor/XC629875_p...|        78|   combuz1|  0.2733807|\n",
      "|wlwwar/XC475384_p...|       108|    wlwwar| 0.99929696|\n",
      "|wlwwar/XC475384_p...|        48|    wlwwar| 0.28950736|\n",
      "|grecor/XC629875_p...|        93|    grecor| 0.58331025|\n",
      "|grecor/XC629875_p...|       147|    hoopoe|  0.5000878|\n",
      "|wlwwar/XC475384_p...|        27|   combuz1|  0.6939817|\n",
      "+--------------------+----------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
