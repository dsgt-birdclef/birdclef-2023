{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- species: string (nullable = true)\n",
      " |-- track_stem: string (nullable = true)\n",
      " |-- track_type: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- embedding: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- prediction_vec: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- predictions: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- rank: long (nullable = true)\n",
      " |    |    |-- index: long (nullable = true)\n",
      " |    |    |-- label: string (nullable = true)\n",
      " |    |    |-- mapped_label: string (nullable = true)\n",
      " |    |    |-- probability: double (nullable = true)\n",
      " |-- start_time: long (nullable = true)\n",
      " |-- energy: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- start_time: long (nullable = true)\n",
      " |-- prediction: string (nullable = true)\n",
      " |-- probability: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- primary_label: string (nullable = true)\n",
      " |-- secondary_labels: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- scientific_name: string (nullable = true)\n",
      " |-- common_name: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- license: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- filename: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from birdclef.utils import get_spark\n",
    "from pyspark.sql import Window, functions as F\n",
    "import os\n",
    "\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"h://spark-tmp/\"\n",
    "\n",
    "spark = get_spark(cores=24, memory=\"40g\")\n",
    "df = spark.read.parquet(\n",
    "    \"../data/processed/birdclef-2023/train_embeddings/consolidated_v4\"\n",
    ")\n",
    "df.printSchema()\n",
    "\n",
    "preds = (\n",
    "    spark.read.parquet(\"../data/processed/birdclef-2023/consolidated_v4_with_preds\")\n",
    "    .repartition(32)\n",
    "    .cache()\n",
    ")\n",
    "preds.printSchema()\n",
    "\n",
    "# also include the metadata\n",
    "birdclef_root = \"../data/raw/birdclef-2023\"\n",
    "train_metadata = spark.read.csv(f\"{birdclef_root}/train_metadata.csv\", header=True)\n",
    "train_metadata.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------------------------------------------------------\n",
      " species        | grecor                                                                           \n",
      " track_stem     | XC629875_part003                                                                 \n",
      " track_type     | source0                                                                          \n",
      " track_name     | grecor/XC629875_part003_source0.mp3                                              \n",
      " embedding      | [0.6731137633323669, 1.1389738321304321, 0.6284520626068115, 0.65399438142776... \n",
      " prediction_vec | [-8.725186347961426, -7.3204827308654785, -9.82101821899414, -10.396224021911... \n",
      " predictions    | [{0, 3026, Tetrastes bonasia_Hazel Grouse, hazgro1, 0.02235649898648262}, {1,... \n",
      " start_time     | 75                                                                               \n",
      " energy         | 0.01598571054637432                                                              \n",
      "-RECORD 1------------------------------------------------------------------------------------------\n",
      " species        | grecor                                                                           \n",
      " track_stem     | XC629875_part005                                                                 \n",
      " track_type     | source3                                                                          \n",
      " track_name     | grecor/XC629875_part005_source3.mp3                                              \n",
      " embedding      | [1.683303713798523, 1.3935127258300781, 0.7466886639595032, 0.250840753316879... \n",
      " prediction_vec | [-13.96982192993164, -12.199172019958496, -11.703277587890625, -13.2876729965... \n",
      " predictions    | [{0, 824, Corvus monedula_Eurasian Jackdaw, eurjac, 0.10154201835393906}, {1,... \n",
      " start_time     | 127                                                                              \n",
      " energy         | 2.1898441314697266                                                               \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=2, vertical=True, truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- track_stem: string (nullable = true)\n",
      " |-- start_time: long (nullable = true)\n",
      " |-- primary_label: string (nullable = true)\n",
      " |-- metadata_species: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- predicted_species: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- predicted_species_prob: array (nullable = false)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- embedding: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- next_embedding: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- track_embedding: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n",
      "-RECORD 0--------------------------------------------------------------------------------------------------\n",
      " track_stem             | XC113284                                                                         \n",
      " start_time             | 0                                                                                \n",
      " primary_label          | bltapa1                                                                          \n",
      " metadata_species       | [bltapa1]                                                                        \n",
      " predicted_species      | [bltapa1, bltapa1, bltapa1, greegr]                                              \n",
      " predicted_species_prob | [0.8905617811747742, 0.8795342373343061, 0.7922798994820364, 0.7029516252475508] \n",
      " embedding              | [1.1686956, 0.51029456, 0.8916889, 1.1414661, 0.68404543, 0.59406203, 1.00071... \n",
      " next_embedding         | [1.046016, 0.53881234, 0.6181147, 1.2281402, 0.84422654, 0.52847487, 1.335799... \n",
      " track_embedding        | [1.1073558, 0.5245534, 0.75490177, 1.1848032, 0.76413596, 0.56126845, 1.16825... \n",
      "-RECORD 1--------------------------------------------------------------------------------------------------\n",
      " track_stem             | XC113284                                                                         \n",
      " start_time             | 5                                                                                \n",
      " primary_label          | bltapa1                                                                          \n",
      " metadata_species       | [bltapa1]                                                                        \n",
      " predicted_species      | [bltapa1, bltapa1, combuz1]                                                      \n",
      " predicted_species_prob | [0.9477298858776589, 0.817868530852032, 0.7044648030567957]                      \n",
      " embedding              | [1.046016, 0.53881234, 0.6181147, 1.2281402, 0.84422654, 0.52847487, 1.335799... \n",
      " next_embedding         | [1.046016, 0.53881234, 0.6181147, 1.2281402, 0.84422654, 0.52847487, 1.335799... \n",
      " track_embedding        | [1.1073558, 0.5245534, 0.75490177, 1.1848032, 0.76413596, 0.56126845, 1.16825... \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@F.udf(returnType=\"array<string>\")\n",
    "def parse_labels(label_str: str):\n",
    "    # use literal eval to parse the string\n",
    "    return ast.literal_eval(label_str)\n",
    "\n",
    "\n",
    "@F.udf(\"array<float>\")\n",
    "def embedding_mean(v):\n",
    "    return np.vstack(v).mean(axis=0).tolist()\n",
    "\n",
    "\n",
    "def xc_id(track_name):\n",
    "    return F.regexp_extract(track_name, r\"XC(\\d+)\", 1)\n",
    "\n",
    "\n",
    "def process(df, train_metadata):\n",
    "    labels = train_metadata.select(\n",
    "        \"primary_label\",\n",
    "        F.array_union(F.array(\"primary_label\"), parse_labels(\"secondary_labels\")).alias(\n",
    "            \"metadata_species\"\n",
    "        ),\n",
    "        xc_id(\"filename\").alias(\"xc_id\"),\n",
    "    )\n",
    "\n",
    "    align_to_window = (\n",
    "        df.where(\"start_time % 5 = 0 or start_time % 2 = 0\")\n",
    "        .join(preds, on=[\"track_name\", \"start_time\"])\n",
    "        .withColumn(\"seq_id\", (F.col(\"start_time\") / 5).cast(\"int\"))\n",
    "        .select(\n",
    "            \"track_stem\",\n",
    "            \"start_time\",\n",
    "            \"seq_id\",\n",
    "            \"embedding\",\n",
    "            \"prediction\",\n",
    "            \"probability\",\n",
    "        )\n",
    "    ).cache()\n",
    "\n",
    "    # compute the current and next embedding\n",
    "    sequence_embedding = (\n",
    "        align_to_window.where(\"track_type = 'original'\")\n",
    "        .groupBy(\"track_stem\", \"seq_id\")\n",
    "        .agg(\n",
    "            F.collect_set(\"embedding\").alias(\"embedding\"),\n",
    "            F.min(\"start_time\").alias(\"start_time\"),\n",
    "        )\n",
    "        .withColumn(\"embedding\", embedding_mean(\"embedding\"))\n",
    "        # also include the next sequence, or the current sequence\n",
    "        .withColumn(\n",
    "            \"next_embedding\",\n",
    "            F.coalesce(\n",
    "                F.lead(\"embedding\", 1).over(\n",
    "                    Window.partitionBy(\"track_stem\").orderBy(\"seq_id\")\n",
    "                ),\n",
    "                \"embedding\",\n",
    "            ),\n",
    "        )\n",
    "        .select(\"track_stem\", \"seq_id\", \"start_time\", \"embedding\", \"next_embedding\")\n",
    "    )\n",
    "\n",
    "    # compute track embedding (global context)\n",
    "    track_embedding = (\n",
    "        # this is the average embedding of all of the sequences\n",
    "        sequence_embedding.groupBy(\"track_stem\")\n",
    "        .agg(F.collect_set(\"embedding\").alias(\"embedding\"))\n",
    "        .select(\"track_stem\", embedding_mean(\"embedding\").alias(\"track_embedding\"))\n",
    "    )\n",
    "\n",
    "    # let's figure out what predictions there are at every sequence id\n",
    "    mixit_predictions = (\n",
    "        align_to_window.where(\"prediction != 'no_call' and probability > 0.7\")\n",
    "        .groupBy(\"track_stem\", \"seq_id\")\n",
    "        .agg(\n",
    "            F.sort_array(\n",
    "                F.collect_list(F.struct(\"probability\", \"prediction\")), asc=False\n",
    "            ).alias(\"values\"),\n",
    "            F.min(\"start_time\").alias(\"start_time\"),\n",
    "        )\n",
    "        .selectExpr(\n",
    "            \"track_stem\",\n",
    "            \"seq_id\",\n",
    "            \"values.prediction as predicted_species\",\n",
    "            \"values.probability as predicted_species_prob\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    track_with_fuzzy_annotations = (\n",
    "        sequence_embedding.join(track_embedding, on=\"track_stem\")\n",
    "        .join(mixit_predictions, on=[\"track_stem\", \"seq_id\"])\n",
    "        .withColumn(\"xc_id\", xc_id(\"track_stem\"))\n",
    "        .join(labels, on=[\"xc_id\"])\n",
    "        .select(\n",
    "            \"track_stem\",\n",
    "            \"start_time\",\n",
    "            \"primary_label\",\n",
    "            \"metadata_species\",\n",
    "            \"predicted_species\",\n",
    "            \"predicted_species_prob\",\n",
    "            \"embedding\",\n",
    "            \"next_embedding\",\n",
    "            \"track_embedding\",\n",
    "        )\n",
    "    )\n",
    "    return track_with_fuzzy_annotations\n",
    "\n",
    "\n",
    "subset = df.where(\"species = 'bltapa1'\").cache()\n",
    "processed_sample = process(subset, train_metadata)\n",
    "processed_sample.printSchema()\n",
    "processed_sample.show(n=2, vertical=True, truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = process(df, train_metadata)\n",
    "processed_df.write.parquet(\n",
    "    \"../data/intermediate/train_postprocessed_v4_00\", mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- track_stem: string (nullable = true)\n",
      " |-- start_time: long (nullable = true)\n",
      " |-- primary_label: string (nullable = true)\n",
      " |-- metadata_species: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- predicted_species: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- predicted_species_prob: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- embedding: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- next_embedding: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- track_embedding: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n",
      "-RECORD 0--------------------------------------------------------------------------------------------------\n",
      " track_stem             | XC109029                                                                         \n",
      " start_time             | 15                                                                               \n",
      " primary_label          | greegr                                                                           \n",
      " metadata_species       | [greegr]                                                                         \n",
      " predicted_species      | [greegr, greegr, greegr, greegr, greegr, greegr]                                 \n",
      " predicted_species_prob | [0.9712775340937801, 0.9643339553704772, 0.9534117166090064, 0.93444535456036... \n",
      " embedding              | [2.3868816, 2.3230796, 1.6890032, 1.1891019, 0.7994075, 0.15464485, 0.2802061... \n",
      " next_embedding         | [1.5500779, 1.677948, 1.0358194, 0.8643622, 0.7883298, 0.45548746, 0.46311468... \n",
      " track_embedding        | [1.8887559, 1.8959149, 0.969237, 1.0064957, 1.0195203, 0.35333478, 0.43932518... \n",
      "-RECORD 1--------------------------------------------------------------------------------------------------\n",
      " track_stem             | XC109029                                                                         \n",
      " start_time             | 30                                                                               \n",
      " primary_label          | greegr                                                                           \n",
      " metadata_species       | [greegr]                                                                         \n",
      " predicted_species      | [greegr, greegr, greegr, greegr, greegr, greegr, categr, categr, categr]         \n",
      " predicted_species_prob | [0.9582731325617099, 0.957884400238543, 0.9533690214825529, 0.949255962221172... \n",
      " embedding              | [2.0056825, 2.4025147, 1.2666123, 1.0325916, 1.0191329, 0.26631376, 0.775911,... \n",
      " next_embedding         | [2.275109, 2.3807173, 1.1886667, 1.1865819, 0.9902519, 0.54579276, 0.67213064... \n",
      " track_embedding        | [1.8887559, 1.8959149, 0.969237, 1.0064957, 1.0195203, 0.35333478, 0.43932518... \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "135324"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = spark.read.parquet(\"../data/intermediate/train_postprocessed_v4_00\")\n",
    "processed_df.printSchema()\n",
    "processed_df.show(n=2, vertical=True, truncate=80)\n",
    "processed_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(\"array<float>\", F.PandasUDFType.SCALAR)\n",
    "def embedding_pair_mean(v1, v2, weight=0.5):\n",
    "    return (v1 * weight + v2 * (1 - weight)) / 2\n",
    "\n",
    "\n",
    "noise_examples = (\n",
    "    df.withColumn(\"probability\", F.col(\"predictions\")[0][\"probability\"])\n",
    "    .where(\"start_time % 3 = 0 and probability < 0.01\")\n",
    "    .orderBy(\"probability\")\n",
    "    .limit(1000)\n",
    "    # take the best example for each track here\n",
    "    .withColumn(\n",
    "        \"rank\",\n",
    "        F.row_number().over(Window.partitionBy(\"track_name\").orderBy(\"probability\")),\n",
    "    )\n",
    "    .where(\"rank = 1\")\n",
    "    .drop(\"rank\")\n",
    "    .select(\"embedding\")\n",
    ")\n",
    "\n",
    "# we choose this value because we want to give more weight to the original\n",
    "# example.\n",
    "weight = F.lit(0.9)\n",
    "augmented_examples = (\n",
    "    processed_df.withColumn(\"species\", F.col(\"metadata_species\")[0])\n",
    "    .withColumn(\n",
    "        \"rank\", F.row_number().over(Window.partitionBy(\"species\").orderBy(F.rand()))\n",
    "    )\n",
    "    .where(\"rank <= 20\")\n",
    "    # now lets cross join with the noise examples\n",
    "    .crossJoin(noise_examples.selectExpr(\"embedding as noise_embedding\").limit(20))\n",
    "    # now randomly keep a subset of these examples\n",
    "    .withColumn(\n",
    "        \"rank\", F.row_number().over(Window.partitionBy(\"species\").orderBy(F.rand()))\n",
    "    )\n",
    "    .where(\"rank <= 20\")\n",
    "    .select(\n",
    "        \"track_stem\",\n",
    "        \"start_time\",\n",
    "        \"primary_label\",\n",
    "        \"metadata_species\",\n",
    "        \"predicted_species\",\n",
    "        \"predicted_species_prob\",\n",
    "        embedding_pair_mean(\"embedding\", \"noise_embedding\", weight).alias(\"embedding\"),\n",
    "        embedding_pair_mean(\"next_embedding\", \"noise_embedding\", weight).alias(\n",
    "            \"next_embedding\"\n",
    "        ),\n",
    "        embedding_pair_mean(\"track_embedding\", \"noise_embedding\", weight).alias(\n",
    "            \"track_embedding\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "processed_with_augmented = augmented_examples.union(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_with_augmented.write.parquet(\n",
    "    \"../data/intermediate/train_postprocessed_v4_01\", mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_with_augmented = spark.read.parquet(\n",
    "    \"../data/intermediate/train_postprocessed_v4_01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------------------------------------------------------------------------------------+\n",
      "|primary_label|                                                                                          coocurring|\n",
      "+-------------+----------------------------------------------------------------------------------------------------+\n",
      "|      abethr1|                                                         [rbsrob1, helgui, eswdov1, rindov, abethr1]|\n",
      "|      abhori1|[amesun2, afghor1, hadibi1, rbsrob1, norfis1, crheag1, vilwea1, spemou2, somgre1, abhori1, egygoo...|\n",
      "|      abythr1|                    [strsee1, abhori1, grbcam1, afrgos1, afdfly1, bswdov1, combul2, rindov, abythr1]|\n",
      "|      afbfly1|                            [piecro1, trobou1, afrgrp1, grbcam1, yertin1, combul2, afbfly1, scrcha1]|\n",
      "|      afdfly1|                            [yewgre1, amesun2, reftin1, afdfly1, yertin1, combul2, chtapa3, tamdov1]|\n",
      "|      afecuc1|[grbcam1, bawhor2, yertin1, klacuc1, didcuc1, tafpri1, yewgre1, blacuc1, afecuc1, somgre1, scthon...|\n",
      "|      affeag1|                                       [somgre1, hadibi1, abhori1, piekin1, affeag1, grecor, rindov]|\n",
      "|      afgfly1|                                                                [ratcis1, kerspa2, combul2, afgfly1]|\n",
      "|      afghor1|[afghor1, piecro1, hadibi1, reedov1, grbcam1, grewoo2, tafpri1, vilwea1, spwlap1, trobou1, blakit...|\n",
      "|      afmdov1|[categr, hadibi1, piekin1, reedov1, tafpri1, blnmou1, pabspa1, slcbou1, abhori1, reccuc1, fotdro5...|\n",
      "|      afpfly1|[piecro1, hadibi1, reedov1, colsun2, carcha1, grbcam1, gyhspa1, klacuc1, afrthr1, vilwea1, afpfly...|\n",
      "|      afpkin1|                                                                                           [afpkin1]|\n",
      "|      afpwag1|[vibsta2, spewea1, amesun2, piecro1, somgre1, afpwag1, reedov1, afrjac1, reccuc1, reftin1, yertin...|\n",
      "|      afrgos1|                   [amesun2, trobou1, hadibi1, somgre1, abhori1, colsun2, afrgos1, eswdov1, litswi1]|\n",
      "|      afrgrp1|                                                                                           [afrgrp1]|\n",
      "|      afrjac1|                                                        [categr, wfbeat1, afrjac1, reedov1, combul2]|\n",
      "|      afrthr1|          [piecro1, sincis1, grbcam1, btweye2, wookin1, rebhor1, afrthr1, combul2, lessts1, gabgos2]|\n",
      "|      amesun2|[amesun2, blbpuf2, hadibi1, reedov1, didcuc1, blnmou1, ratcis1, somgre1, abhori1, affeag1, combul...|\n",
      "|      augbuz1|                                                                                  [blaplo1, augbuz1]|\n",
      "|      bagwea1|                                              [trobou1, kerspa2, grbcam1, affeag1, gycwar3, bagwea1]|\n",
      "+-------------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now let's handle some filtering of the data.\n",
    "# we'll generate a list of allowable overlapping species\n",
    "\n",
    "coocurring = (\n",
    "    processed_df.select(\n",
    "        \"primary_label\", F.explode(\"metadata_species\").alias(\"exploded_species\")\n",
    "    )\n",
    "    .groupBy(\"primary_label\")\n",
    "    .agg(F.collect_set(\"exploded_species\").alias(\"coocurring\"))\n",
    ")\n",
    "\n",
    "coocurring.show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- primary_label: string (nullable = true)\n",
      " |-- track_stem: string (nullable = true)\n",
      " |-- start_time: long (nullable = true)\n",
      " |-- metadata_species: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- predicted_species: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- embedding: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- next_embedding: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- track_embedding: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n",
      "-RECORD 0---------------------------------------------------------------------------------------------\n",
      " primary_label     | ccbeat1                                                                          \n",
      " track_stem        | XC120632                                                                         \n",
      " start_time        | 5                                                                                \n",
      " metadata_species  | [ccbeat1]                                                                        \n",
      " predicted_species | [ccbeat1, trobou1]                                                               \n",
      " embedding         | [1.523604, 0.9732575, 0.689221, 1.3162022, 0.715711, 0.76590884, 0.63761246, ... \n",
      " next_embedding    | [1.1461543, 0.8640864, 0.45597965, 1.3028704, 0.9476467, 0.6115093, 1.2030749... \n",
      " track_embedding   | [1.3749335, 0.8206999, 0.59814745, 1.2513487, 0.74043876, 0.81131864, 0.95881... \n",
      "-RECORD 1---------------------------------------------------------------------------------------------\n",
      " primary_label     | ccbeat1                                                                          \n",
      " track_stem        | XC235951                                                                         \n",
      " start_time        | 10                                                                               \n",
      " metadata_species  | [ccbeat1]                                                                        \n",
      " predicted_species | [ccbeat1]                                                                        \n",
      " embedding         | [1.3187864, 0.7150727, 0.9900959, 1.8962469, 0.6126626, 1.2224292, 0.72379476... \n",
      " next_embedding    | [1.048248, 0.59235334, 1.1732999, 1.5403138, 1.0197676, 0.97606707, 0.9459938... \n",
      " track_embedding   | [1.2631669, 0.7206624, 0.96723706, 1.7925037, 0.73821354, 1.1108525, 0.853876... \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[track_stem: string, start_time: bigint, predicted_species: array<string>, metadata_species: array<string>, predict_count: bigint]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_df = (\n",
    "    processed_with_augmented.join(coocurring, on=\"primary_label\")\n",
    "    .withColumn(\n",
    "        \"predicted_species\", F.array_intersect(\"predicted_species\", \"coocurring\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"predicted_species\",\n",
    "        F.when(F.size(\"predicted_species\") == 0, F.array(\"primary_label\")).otherwise(\n",
    "            F.col(\"predicted_species\")\n",
    "        ),\n",
    "    )\n",
    "    .drop(\"coocurring\")\n",
    "    .drop(\"predicted_species_prob\")\n",
    ")\n",
    "filtered_train_df.printSchema()\n",
    "filtered_train_df.show(n=2, vertical=True, truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_df.write.parquet(\n",
    "    \"../data/processed/birdclef-2023/train_postprocessed/v4\", mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140604"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_df = spark.read.parquet(\n",
    "    \"../data/processed/birdclef-2023/train_postprocessed/v4\"\n",
    ")\n",
    "filtered_train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+------------------+-------------+\n",
      "|track_stem|start_time|   predicted_species|  metadata_species|predict_count|\n",
      "+----------+----------+--------------------+------------------+-------------+\n",
      "|  XC462100|         0|  [reccuc1, grbcam1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|         5|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        10|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        15|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        20|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        25|           [grbcam1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        30|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        35|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        40|  [reccuc1, grbcam1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        45|  [grbcam1, abhori1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        50|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        55|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        60|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        65|           [grbcam1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        70|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        75|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        80|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        85|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        90|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        90|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        90|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|        95|           [reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|       100|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|       105|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|       110|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|       115|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|       120|  [reccuc1, grbcam1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|       125|[reccuc1, grbcam1...|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|       130|[grbcam1, reccuc1...|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|       135|[reccuc1, colsun2...|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|       140|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|       145|  [grbcam1, reccuc1]|[grbcam1, reccuc1]|           65|\n",
      "|  XC462100|       150|           [grbcam1]|[grbcam1, reccuc1]|           65|\n",
      "+----------+----------+--------------------+------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = (\n",
    "    filtered_train_df.withColumn(\n",
    "        \"predict_count\",\n",
    "        F.sum(F.size(\"predicted_species\")).over(Window.partitionBy(\"track_stem\")),\n",
    "    )\n",
    "    .withColumn(\"rank\", F.rank().over(Window.orderBy(F.desc(\"predict_count\"))))\n",
    "    .where(\"rank = 1\")\n",
    "    .orderBy(\"start_time\")\n",
    "    .select(\n",
    "        \"track_stem\",\n",
    "        \"start_time\",\n",
    "        \"predicted_species\",\n",
    "        \"metadata_species\",\n",
    "        \"predict_count\",\n",
    "    )\n",
    ")\n",
    "example.show(n=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
