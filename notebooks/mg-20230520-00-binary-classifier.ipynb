{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classifier (call/no call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdclef.utils import get_spark\n",
    "\n",
    "spark = get_spark(cores=4, memory=\"10g\")\n",
    "df = spark.read.parquet(\n",
    "    \"../data/processed/birdclef-2023/train_embeddings/consolidated_v3\"\n",
    ")\n",
    "df.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Positive labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window, functions as F\n",
    "\n",
    "# keep the track_type for the highest energy\n",
    "highest_energy_channel = (\n",
    "    df\n",
    "    # get the track stem without the part\n",
    "    .withColumn(\"original_track_stem\", F.split(F.col(\"track_stem\"), \"_\").getItem(0))\n",
    "    .where(\"track_type != 'original'\")\n",
    "    # get the track type that has the most energy\n",
    "    .withColumn(\n",
    "        \"rank\",\n",
    "        F.rank().over(\n",
    "            Window.partitionBy(\"original_track_stem\").orderBy(F.desc(\"energy\"))\n",
    "        ),\n",
    "    )\n",
    "    # keep the first row\n",
    "    .where(F.col(\"rank\") == 1)\n",
    "    # drop the rank column\n",
    "    .select(\"species\", \"track_stem\", \"track_type\")\n",
    "    .distinct()\n",
    ")\n",
    "\n",
    "# get the highest predictions by exploding the values\n",
    "exploded_embeddings = (\n",
    "    df\n",
    "    # join against the highest energy channel\n",
    "    .join(\n",
    "        highest_energy_channel,\n",
    "        on=[\"species\", \"track_stem\", \"track_type\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    # explode the embeddings, these are ordered by confidence\n",
    "    .withColumn(\"predictions\", F.explode(\"predictions\")).select(\n",
    "        \"species\",\n",
    "        \"track_stem\",\n",
    "        \"track_type\",\n",
    "        \"start_time\",\n",
    "        \"track_name\",\n",
    "        \"embedding\",\n",
    "        \"predictions.*\",\n",
    "    )\n",
    "    # simplifying assumption: we assume the prediction with the highest confidence is the true label\n",
    "    .where(\"rank = 0\")\n",
    ").cache()\n",
    "\n",
    "exploded_embeddings.drop(\"embedding\").show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick count of the number of species\n",
    "counts = (\n",
    "    exploded_embeddings.groupBy(\"species\")\n",
    "    .agg(F.count(\"*\").alias(\"n\"))\n",
    "    .orderBy(F.desc(\"n\"))\n",
    ")\n",
    "counts.show(n=5)\n",
    "counts.orderBy(\"n\").show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepared DF\n",
    "rarity_min_count = 100\n",
    "rare_species_count = (\n",
    "    exploded_embeddings.groupBy(\"species\")\n",
    "    .agg(F.count(\"*\").alias(\"n\"))\n",
    "    .where(f\"n < {rarity_min_count}\")\n",
    ")\n",
    "rare_species_count.show(n=5)\n",
    "\n",
    "# if there are a lot of examples, we can use a higher threshold\n",
    "common_species = exploded_embeddings.where(\"probability > 0.4\").join(\n",
    "    rare_species_count.select(\"species\"), on=\"species\", how=\"left_anti\"\n",
    ")\n",
    "# these ones are less common so we use a lower threshold so we have at least one\n",
    "# example for each species\n",
    "rare_species = exploded_embeddings.where(\"probability > 0.1\").join(\n",
    "    rare_species_count.select(\"species\"), on=\"species\", how=\"inner\"\n",
    ")\n",
    "prepared = common_species.union(rare_species).select(\n",
    "    \"species\", \"probability\", \"embedding\"\n",
    ")\n",
    "prepared.show(n=5)\n",
    "prepared.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check that we have the right number of classes, and how many examples we are working with\n",
    "prepared_counts = (\n",
    "    prepared.groupBy(\"species\").agg(F.count(\"*\").alias(\"n\")).orderBy(F.desc(\"n\"))\n",
    ")\n",
    "print(f\"number of species {prepared_counts.count()}\")\n",
    "\n",
    "prepared_counts.show(n=5)\n",
    "prepared_counts.orderBy(\"n\").show(n=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Negative labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative calls\n",
    "noise_indices = [\n",
    "    (1022, \"Dog_Dog\"),\n",
    "    (1136, \"Engine_Engine\"),\n",
    "    (1141, \"Environmental_Environmental\"),\n",
    "    (1219, \"Fireworks_Fireworks\"),\n",
    "    (1352, \"Gun_Gun\"),\n",
    "    (1449, \"Human non-vocal_Human non-vocal\"),\n",
    "    (1450, \"Human vocal_Human vocal\"),\n",
    "    (1451, \"Human whistle_Human whistle\"),\n",
    "    (1997, \"Noise_Noise\"),\n",
    "    (2812, \"Siren_Siren\"),\n",
    "]\n",
    "noise_indices = [i[0] for i in noise_indices]\n",
    "\n",
    "# Craete negative samples DF\n",
    "negative_samples = (\n",
    "    df\n",
    "    # explode the predictions with their indices\n",
    "    .select(\n",
    "        \"track_name\",\n",
    "        \"start_time\",\n",
    "        \"embedding\",\n",
    "        F.posexplode(\"prediction_vec\").alias(\"index\", \"logit\"),\n",
    "    )\n",
    "    .where(F.col(\"index\").isin(noise_indices))\n",
    "    .withColumn(\"probability\", F.expr(\"1/(1+exp(-logit))\"))\n",
    "    .where(\"probability > 0.4\")\n",
    "    .select(\"track_name\", \"start_time\", F.lit(\"no_call\").alias(\"species\"), \"embedding\")\n",
    ").cache()\n",
    "negative_samples.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Get the exploded examples\n",
    "# Only keep examples less than 0.1\n",
    "# Every example in the new query is a no-call\n",
    "# Union with the negative_samples\n",
    "\n",
    "exploded_negatives = exploded_embeddings.where(exploded_embeddings.probability < 0.1)\n",
    "\n",
    "# Define fractions for each stratum\n",
    "fractions = (\n",
    "    exploded_negatives.select(\"track_stem\")\n",
    "    .distinct()\n",
    "    .withColumn(\"fraction\", lit(0.6))\n",
    "    .rdd.collectAsMap()\n",
    ")\n",
    "\n",
    "# Perform stratified sampling\n",
    "exploded_negative_sub = exploded_negatives.stat.sampleBy(\n",
    "    \"track_stem\", fractions, seed=42\n",
    ")\n",
    "\n",
    "# Select columns from exploded DF that match negative_samples\n",
    "exploded_negative_select = exploded_negative_sub.select(negative_samples.columns)\n",
    "\n",
    "# Perform union operation\n",
    "negatives = negative_samples.union(exploded_negative_select)\n",
    "\n",
    "# Set all values in species column to \"no_call\"\n",
    "negatives = negatives.withColumn(\"species\", lit(\"no_call\"))\n",
    "\n",
    "# Check unique values\n",
    "unique_vals = negatives.select(\"species\").distinct()\n",
    "unique_values_list = unique_vals.rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "print(f\"Unique values in species column: {len(unique_values_list)}\")\n",
    "print(f\"Number of rows: {negatives.count()}\")\n",
    "negatives.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_sub = negatives.select(\"species\", \"embedding\")\n",
    "positives_sub = prepared.select(\"species\", \"embedding\")\n",
    "positives_sub = positives_sub.withColumn(\"species\", lit(\"call\"))\n",
    "binary_df = negatives_sub.union(positives_sub)\n",
    "binary_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of samples for each label\n",
    "# counts = binary_df.groupBy(\"species\").agg(F.count(\"*\").alias(\"n\")).orderBy(F.desc(\"n\"))\n",
    "# counts.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for model training\n",
    "data = binary_df.toPandas()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.stack(data[\"embedding\"]),\n",
    "    data[\"species\"],\n",
    "    test_size=0.33,\n",
    "    stratify=data[\"species\"],\n",
    ")\n",
    "\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target with label encoder\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Data shape\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(truth, preds):\n",
    "    print(\"Accuracy:\", round(accuracy_score(truth, preds), 3))\n",
    "    print(\"Precision:\", round(precision_score(truth, preds, average=\"macro\"), 3))\n",
    "    print(\"Recall:\", round(recall_score(truth, preds, average=\"macro\"), 3))\n",
    "    print(\"F1 Score:\", round(f1_score(truth, preds, average=\"macro\"), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "weights = class_weight.compute_sample_weight(class_weight=\"balanced\", y=y_train_enc)\n",
    "\n",
    "# LogisticRegression\n",
    "lgr_search = BayesSearchCV(\n",
    "    LogisticRegression(),\n",
    "    {\n",
    "        \"penalty\": (\"l2\",),\n",
    "        \"C\": (0.01, 1.1, \"log-uniform\"),\n",
    "    },\n",
    "    n_iter=10,\n",
    "    scoring=\"f1\",\n",
    "    verbose=4,\n",
    "    cv=3,\n",
    "    n_points=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "%time lgr_search.fit(X_train, y_train_enc, sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "model_eval(y_test_enc, lgr_search.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "weights = class_weight.compute_sample_weight(class_weight=\"balanced\", y=y_train_enc)\n",
    "\n",
    "# XGBoost model\n",
    "xgb_search = BayesSearchCV(\n",
    "    XGBClassifier(tree_method=\"gpu_hist\"),\n",
    "    {\n",
    "        \"eta\": (0.01, 1.0, \"log-uniform\"),\n",
    "        \"max_depth\": (1, 30, \"uniform\"),\n",
    "        \"gamma\": (0, 1, \"uniform\"),\n",
    "        \"min_child_weight\": (1, 10, \"uniform\"),\n",
    "    },\n",
    "    n_iter=10,\n",
    "    scoring=\"f1\",\n",
    "    verbose=4,\n",
    "    cv=3,\n",
    "    n_points=1,\n",
    "    n_jobs=1,\n",
    ")\n",
    "%time xgb_search.fit(X_train, y_train_enc, sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "model_eval(y_test_enc, xgb_search.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
