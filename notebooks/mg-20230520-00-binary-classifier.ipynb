{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classifier (call/no call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/21 18:05:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- species: string (nullable = true)\n",
      " |-- track_stem: string (nullable = true)\n",
      " |-- track_type: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- embedding: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- prediction_vec: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- predictions: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- rank: long (nullable = true)\n",
      " |    |    |-- index: long (nullable = true)\n",
      " |    |    |-- label: string (nullable = true)\n",
      " |    |    |-- mapped_label: string (nullable = true)\n",
      " |    |    |-- probability: double (nullable = true)\n",
      " |-- start_time: long (nullable = true)\n",
      " |-- energy: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from birdclef.utils import get_spark\n",
    "\n",
    "spark = get_spark(cores=4, memory=\"10g\")\n",
    "df = spark.read.parquet(\n",
    "    \"../data/processed/birdclef-2023/train_embeddings/consolidated_v3\"\n",
    ")\n",
    "df.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Positive labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:==================================================>    (184 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+----------+--------------------+----+-----+--------------------+------------+--------------------+\n",
      "|species|track_stem|track_type|start_time|          track_name|rank|index|               label|mapped_label|         probability|\n",
      "+-------+----------+----------+----------+--------------------+----+-----+--------------------+------------+--------------------+\n",
      "|abythr1|  XC233199|   source0|         0|abythr1/XC233199_...|   0|  639|Chloropsis hardwi...|     orblea1|0.002208352088928...|\n",
      "|abythr1|  XC233199|   source0|        57|abythr1/XC233199_...|   0| 1151|Erpornis zanthole...|     whbyuh1|0.025502817705273628|\n",
      "|abythr1|  XC233199|   source0|        27|abythr1/XC233199_...|   0| 3164|Turdus abyssinicu...|     abythr1|0.024902962148189545|\n",
      "|abythr1|  XC233199|   source0|        30|abythr1/XC233199_...|   0|  639|Chloropsis hardwi...|     orblea1|0.012038093991577625|\n",
      "|abythr1|  XC233199|   source0|        21|abythr1/XC233199_...|   0| 3185|Turdus leucomelas...|     pabthr1|  0.7510073781013489|\n",
      "+-------+----------+----------+----------+--------------------+----+-----+--------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window, functions as F\n",
    "\n",
    "# keep the track_type for the highest energy\n",
    "highest_energy_channel = (\n",
    "    df\n",
    "    # get the track stem without the part\n",
    "    .withColumn(\"original_track_stem\", F.split(F.col(\"track_stem\"), \"_\").getItem(0))\n",
    "    .where(\"track_type != 'original'\")\n",
    "    # get the track type that has the most energy\n",
    "    .withColumn(\n",
    "        \"rank\",\n",
    "        F.rank().over(\n",
    "            Window.partitionBy(\"original_track_stem\").orderBy(F.desc(\"energy\"))\n",
    "        ),\n",
    "    )\n",
    "    # keep the first row\n",
    "    .where(F.col(\"rank\") == 1)\n",
    "    # drop the rank column\n",
    "    .select(\"species\", \"track_stem\", \"track_type\")\n",
    "    .distinct()\n",
    ")\n",
    "\n",
    "# get the highest predictions by exploding the values\n",
    "exploded_embeddings = (\n",
    "    df\n",
    "    # join against the highest energy channel\n",
    "    .join(\n",
    "        highest_energy_channel,\n",
    "        on=[\"species\", \"track_stem\", \"track_type\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    # explode the embeddings, these are ordered by confidence\n",
    "    .withColumn(\"predictions\", F.explode(\"predictions\")).select(\n",
    "        \"species\",\n",
    "        \"track_stem\",\n",
    "        \"track_type\",\n",
    "        \"start_time\",\n",
    "        \"track_name\",\n",
    "        \"embedding\",\n",
    "        \"predictions.*\",\n",
    "    )\n",
    "    # simplifying assumption: we assume the prediction with the highest confidence is the true label\n",
    "    .where(\"rank = 0\")\n",
    ").cache()\n",
    "\n",
    "exploded_embeddings.drop(\"embedding\").show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|species|    n|\n",
      "+-------+-----+\n",
      "|thrnig1|12987|\n",
      "| wlwwar| 9249|\n",
      "|combuz1| 7173|\n",
      "| hoopoe| 6731|\n",
      "| barswa| 6191|\n",
      "+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:====================================================> (195 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|species|  n|\n",
      "+-------+---+\n",
      "|afpkin1|  3|\n",
      "|whhsaw1|  4|\n",
      "|whctur2|  4|\n",
      "|golher1|  5|\n",
      "|lotlap1|  8|\n",
      "+-------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# quick count of the number of species\n",
    "counts = (\n",
    "    exploded_embeddings.groupBy(\"species\")\n",
    "    .agg(F.count(\"*\").alias(\"n\"))\n",
    "    .orderBy(F.desc(\"n\"))\n",
    ")\n",
    "counts.show(n=5)\n",
    "counts.orderBy(\"n\").show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|species|  n|\n",
      "+-------+---+\n",
      "|purgre2| 60|\n",
      "|bubwar2| 90|\n",
      "|rehwea1| 69|\n",
      "|kvbsun1| 80|\n",
      "|equaka1| 63|\n",
      "+-------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+\n",
      "|species|       probability|           embedding|\n",
      "+-------+------------------+--------------------+\n",
      "|afghor1|0.9965255856513977|[0.57833033800125...|\n",
      "|afghor1| 0.511886715888977|[1.00166213512420...|\n",
      "|afghor1|0.9984956979751587|[0.88829582929611...|\n",
      "|afghor1|0.9988522529602051|[1.26016914844512...|\n",
      "|afghor1|0.9997662901878357|[1.16302716732025...|\n",
      "+-------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74126"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepared DF\n",
    "rarity_min_count = 100\n",
    "rare_species_count = (\n",
    "    exploded_embeddings.groupBy(\"species\")\n",
    "    .agg(F.count(\"*\").alias(\"n\"))\n",
    "    .where(f\"n < {rarity_min_count}\")\n",
    ")\n",
    "rare_species_count.show(n=5)\n",
    "\n",
    "# if there are a lot of examples, we can use a higher threshold\n",
    "common_species = exploded_embeddings.where(\"probability > 0.4\").join(\n",
    "    rare_species_count.select(\"species\"), on=\"species\", how=\"left_anti\"\n",
    ")\n",
    "# these ones are less common so we use a lower threshold so we have at least one\n",
    "# example for each species\n",
    "rare_species = exploded_embeddings.where(\"probability > 0.1\").join(\n",
    "    rare_species_count.select(\"species\"), on=\"species\", how=\"inner\"\n",
    ")\n",
    "prepared = common_species.union(rare_species).select(\n",
    "    \"species\", \"probability\", \"embedding\"\n",
    ")\n",
    "prepared.show(n=5)\n",
    "prepared.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of species 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|species|   n|\n",
      "+-------+----+\n",
      "|thrnig1|3833|\n",
      "| hoopoe|3822|\n",
      "|eubeat1|3116|\n",
      "| wlwwar|2687|\n",
      "| barswa|2603|\n",
      "+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|species|  n|\n",
      "+-------+---+\n",
      "|afpkin1|  2|\n",
      "|whhsaw1|  2|\n",
      "|rehblu1|  2|\n",
      "|golher1|  3|\n",
      "|lotlap1|  3|\n",
      "+-------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets check that we have the right number of classes, and how many examples we are working with\n",
    "prepared_counts = (\n",
    "    prepared.groupBy(\"species\").agg(F.count(\"*\").alias(\"n\")).orderBy(F.desc(\"n\"))\n",
    ")\n",
    "print(f\"number of species {prepared_counts.count()}\")\n",
    "\n",
    "prepared_counts.show(n=5)\n",
    "prepared_counts.orderBy(\"n\").show(n=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Negative labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 157:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------+--------------------+\n",
      "|          track_name|start_time|species|           embedding|\n",
      "+--------------------+----------+-------+--------------------+\n",
      "|hoopoe/XC318438_p...|        66|no_call|[0.47851136326789...|\n",
      "|litegr/XC332323_p...|       117|no_call|[0.38947930932044...|\n",
      "|litegr/XC332323_p...|        12|no_call|[0.43516066670417...|\n",
      "|litegr/XC332323_p...|        12|no_call|[0.43516066670417...|\n",
      "|litegr/XC332727_p...|        78|no_call|[0.35861393809318...|\n",
      "|litegr/XC331548_p...|        90|no_call|[0.51571053266525...|\n",
      "|eubeat1/XC699304_...|         9|no_call|[0.13348712027072...|\n",
      "|combuz1/XC579930_...|        33|no_call|[0.22507806122303...|\n",
      "|barswa/XC361240_p...|         0|no_call|[1.25061154365539...|\n",
      "|combuz1/XC579874_...|        30|no_call|[0.03499644994735...|\n",
      "|spmthr1/XC602624_...|       123|no_call|[1.07436048984527...|\n",
      "|blaplo1/XC736812_...|        72|no_call|[0.12970589101314...|\n",
      "|egygoo/XC109700_s...|        72|no_call|[0.26487210392951...|\n",
      "|grecor/XC505211_s...|        36|no_call|[0.57878917455673...|\n",
      "|cohmar1/XC748722_...|        24|no_call|[0.91182446479797...|\n",
      "|scrcha1/XC400413_...|        39|no_call|[1.38340187072753...|\n",
      "|gnbcam2/XC205678_...|         0|no_call|[0.75772899389266...|\n",
      "|rindov/XC717007_s...|        57|no_call|[0.45265802741050...|\n",
      "|chtapa3/XC703484_...|         9|no_call|[1.00851356983184...|\n",
      "|blacuc1/XC390504_...|        36|no_call|[0.55738186836242...|\n",
      "+--------------------+----------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Negative calls\n",
    "noise_indices = [\n",
    "    (1022, \"Dog_Dog\"),\n",
    "    (1136, \"Engine_Engine\"),\n",
    "    (1141, \"Environmental_Environmental\"),\n",
    "    (1219, \"Fireworks_Fireworks\"),\n",
    "    (1352, \"Gun_Gun\"),\n",
    "    (1449, \"Human non-vocal_Human non-vocal\"),\n",
    "    (1450, \"Human vocal_Human vocal\"),\n",
    "    (1451, \"Human whistle_Human whistle\"),\n",
    "    (1997, \"Noise_Noise\"),\n",
    "    (2812, \"Siren_Siren\"),\n",
    "]\n",
    "noise_indices = [i[0] for i in noise_indices]\n",
    "\n",
    "# Craete negative samples DF\n",
    "negative_samples = (\n",
    "    df\n",
    "    # explode the predictions with their indices\n",
    "    .select(\n",
    "        \"track_name\",\n",
    "        \"start_time\",\n",
    "        \"embedding\",\n",
    "        F.posexplode(\"prediction_vec\").alias(\"index\", \"logit\"),\n",
    "    )\n",
    "    .where(F.col(\"index\").isin(noise_indices))\n",
    "    .withColumn(\"probability\", F.expr(\"1/(1+exp(-logit))\"))\n",
    "    .where(\"probability > 0.4\")\n",
    "    .select(\"track_name\", \"start_time\", F.lit(\"no_call\").alias(\"species\"), \"embedding\")\n",
    ").cache()\n",
    "negative_samples.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in species column: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 58978\n",
      "+--------------------+----------+-------+--------------------+\n",
      "|          track_name|start_time|species|           embedding|\n",
      "+--------------------+----------+-------+--------------------+\n",
      "|hoopoe/XC318438_p...|        66|no_call|[0.47851136326789...|\n",
      "|litegr/XC332323_p...|       117|no_call|[0.38947930932044...|\n",
      "|litegr/XC332323_p...|        12|no_call|[0.43516066670417...|\n",
      "|litegr/XC332323_p...|        12|no_call|[0.43516066670417...|\n",
      "|litegr/XC332727_p...|        78|no_call|[0.35861393809318...|\n",
      "+--------------------+----------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Get the exploded examples\n",
    "# Only keep examples less than 0.1\n",
    "# Every example in the new query is a no-call\n",
    "# Union with the negative_samples\n",
    "\n",
    "exploded_negatives = exploded_embeddings.where(exploded_embeddings.probability < 0.1)\n",
    "\n",
    "# Define fractions for each stratum\n",
    "fractions = (\n",
    "    exploded_negatives.select(\"track_stem\")\n",
    "    .distinct()\n",
    "    .withColumn(\"fraction\", lit(0.6))\n",
    "    .rdd.collectAsMap()\n",
    ")\n",
    "\n",
    "# Perform stratified sampling\n",
    "exploded_negative_sub = exploded_negatives.stat.sampleBy(\n",
    "    \"track_stem\", fractions, seed=42\n",
    ")\n",
    "\n",
    "# Select columns from exploded DF that match negative_samples\n",
    "exploded_negative_select = exploded_negative_sub.select(negative_samples.columns)\n",
    "\n",
    "# Perform union operation\n",
    "negatives = negative_samples.union(exploded_negative_select)\n",
    "\n",
    "# Set all values in species column to \"no_call\"\n",
    "negatives = negatives.withColumn(\"species\", lit(\"no_call\"))\n",
    "\n",
    "# Check unique values\n",
    "unique_vals = negatives.select(\"species\").distinct()\n",
    "unique_values_list = unique_vals.rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "print(f\"Unique values in species column: {len(unique_values_list)}\")\n",
    "print(f\"Number of rows: {negatives.count()}\")\n",
    "negatives.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 214:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|species|           embedding|\n",
      "+-------+--------------------+\n",
      "|no_call|[0.47851136326789...|\n",
      "|no_call|[0.38947930932044...|\n",
      "|no_call|[0.43516066670417...|\n",
      "|no_call|[0.43516066670417...|\n",
      "|no_call|[0.35861393809318...|\n",
      "|no_call|[0.51571053266525...|\n",
      "|no_call|[0.13348712027072...|\n",
      "|no_call|[0.22507806122303...|\n",
      "|no_call|[1.25061154365539...|\n",
      "|no_call|[0.03499644994735...|\n",
      "|no_call|[1.07436048984527...|\n",
      "|no_call|[0.12970589101314...|\n",
      "|no_call|[0.26487210392951...|\n",
      "|no_call|[0.57878917455673...|\n",
      "|no_call|[0.91182446479797...|\n",
      "|no_call|[1.38340187072753...|\n",
      "|no_call|[0.75772899389266...|\n",
      "|no_call|[0.45265802741050...|\n",
      "|no_call|[1.00851356983184...|\n",
      "|no_call|[0.55738186836242...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "negatives_sub = negatives.select(\"species\", \"embedding\")\n",
    "positives_sub = prepared.select(\"species\", \"embedding\")\n",
    "positives_sub = positives_sub.withColumn(\"species\", lit(\"call\"))\n",
    "binary_df = negatives_sub.union(positives_sub)\n",
    "binary_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of samples for each label\n",
    "# counts = binary_df.groupBy(\"species\").agg(F.count(\"*\").alias(\"n\")).orderBy(F.desc(\"n\"))\n",
    "# counts.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_call</td>\n",
       "      <td>[0.47851136326789856, 1.983388900756836, 1.091...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_call</td>\n",
       "      <td>[0.38947930932044983, 1.2773804664611816, 0.54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_call</td>\n",
       "      <td>[0.43516066670417786, 1.339859962463379, 1.467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no_call</td>\n",
       "      <td>[0.43516066670417786, 1.339859962463379, 1.467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no_call</td>\n",
       "      <td>[0.3586139380931854, 1.1902474164962769, 0.520...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species                                          embedding\n",
       "0  no_call  [0.47851136326789856, 1.983388900756836, 1.091...\n",
       "1  no_call  [0.38947930932044983, 1.2773804664611816, 0.54...\n",
       "2  no_call  [0.43516066670417786, 1.339859962463379, 1.467...\n",
       "3  no_call  [0.43516066670417786, 1.339859962463379, 1.467...\n",
       "4  no_call  [0.3586139380931854, 1.1902474164962769, 0.520..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data for model training\n",
    "data = binary_df.toPandas()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89179, 320) (43925, 320)\n",
      "(89179,) (43925,)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.stack(data[\"embedding\"]),\n",
    "    data[\"species\"],\n",
    "    test_size=0.33,\n",
    "    stratify=data[\"species\"],\n",
    ")\n",
    "\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target with label encoder\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Data shape\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(truth, preds):\n",
    "    print(\"Accuracy:\", round(accuracy_score(truth, preds), 3))\n",
    "    print(\"Precision:\", round(precision_score(truth, preds, average=\"macro\"), 3))\n",
    "    print(\"Recall:\", round(recall_score(truth, preds, average=\"macro\"), 3))\n",
    "    print(\"F1 Score:\", round(f1_score(truth, preds, average=\"macro\"), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 2/3] END .C=0.01234221467268603, penalty=l2;, score=0.845 total time=   3.5s\n",
      "[CV 1/3] END .C=0.01234221467268603, penalty=l2;, score=0.843 total time=   4.4s\n",
      "[CV 3/3] END .C=0.01234221467268603, penalty=l2;, score=0.846 total time=   4.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 3/3] END C=0.017726603616353892, penalty=l2;, score=0.846 total time=   3.2s\n",
      "[CV 2/3] END C=0.017726603616353892, penalty=l2;, score=0.845 total time=   4.1s\n",
      "[CV 1/3] END C=0.017726603616353892, penalty=l2;, score=0.843 total time=   4.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END ..C=0.5143277701683105, penalty=l2;, score=0.843 total time=   3.3s\n",
      "[CV 2/3] END ..C=0.5143277701683105, penalty=l2;, score=0.845 total time=   4.1s\n",
      "[CV 3/3] END ..C=0.5143277701683105, penalty=l2;, score=0.846 total time=   4.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 3/3] END ..C=0.8534484371066713, penalty=l2;, score=0.846 total time=   3.1s\n",
      "[CV 1/3] END ..C=0.8534484371066713, penalty=l2;, score=0.843 total time=   4.2s\n",
      "[CV 2/3] END ..C=0.8534484371066713, penalty=l2;, score=0.845 total time=   4.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 2/3] END ..C=0.8178172148884149, penalty=l2;, score=0.845 total time=   3.3s\n",
      "[CV 1/3] END ..C=0.8178172148884149, penalty=l2;, score=0.843 total time=   4.2s\n",
      "[CV 3/3] END ..C=0.8178172148884149, penalty=l2;, score=0.846 total time=   4.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 2/3] END .C=0.03173433399880168, penalty=l2;, score=0.845 total time=   3.0s\n",
      "[CV 3/3] END .C=0.03173433399880168, penalty=l2;, score=0.846 total time=   4.1s\n",
      "[CV 1/3] END .C=0.03173433399880168, penalty=l2;, score=0.843 total time=   4.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 2/3] END ..C=0.6696692237537835, penalty=l2;, score=0.845 total time=   3.2s\n",
      "[CV 1/3] END ..C=0.6696692237537835, penalty=l2;, score=0.843 total time=   3.7s\n",
      "[CV 3/3] END ..C=0.6696692237537835, penalty=l2;, score=0.846 total time=   4.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 2/3] END C=0.025796798150282674, penalty=l2;, score=0.845 total time=   3.7s\n",
      "[CV 1/3] END C=0.025796798150282674, penalty=l2;, score=0.843 total time=   4.1s\n",
      "[CV 3/3] END C=0.025796798150282674, penalty=l2;, score=0.846 total time=   4.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END ..C=0.1370703865183556, penalty=l2;, score=0.843 total time=   3.1s\n",
      "[CV 2/3] END ..C=0.1370703865183556, penalty=l2;, score=0.845 total time=   3.7s\n",
      "[CV 3/3] END ..C=0.1370703865183556, penalty=l2;, score=0.846 total time=   4.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 3/3] END .C=0.04474572438004226, penalty=l2;, score=0.846 total time=   3.3s\n",
      "[CV 2/3] END .C=0.04474572438004226, penalty=l2;, score=0.845 total time=   4.4s\n",
      "[CV 1/3] END .C=0.04474572438004226, penalty=l2;, score=0.843 total time=   4.4s\n",
      "CPU times: user 10.6 s, sys: 3.02 s, total: 13.7 s\n",
      "Wall time: 48.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=3, estimator=LogisticRegression(), n_iter=10, n_jobs=-1,\n",
       "              scoring=&#x27;f1&#x27;,\n",
       "              search_spaces={&#x27;C&#x27;: (0.01, 1.1, &#x27;log-uniform&#x27;),\n",
       "                             &#x27;penalty&#x27;: (&#x27;l2&#x27;,)},\n",
       "              verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=3, estimator=LogisticRegression(), n_iter=10, n_jobs=-1,\n",
       "              scoring=&#x27;f1&#x27;,\n",
       "              search_spaces={&#x27;C&#x27;: (0.01, 1.1, &#x27;log-uniform&#x27;),\n",
       "                             &#x27;penalty&#x27;: (&#x27;l2&#x27;,)},\n",
       "              verbose=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=3, estimator=LogisticRegression(), n_iter=10, n_jobs=-1,\n",
       "              scoring='f1',\n",
       "              search_spaces={'C': (0.01, 1.1, 'log-uniform'),\n",
       "                             'penalty': ('l2',)},\n",
       "              verbose=4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt.space import Real\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "weights = class_weight.compute_sample_weight(class_weight=\"balanced\", y=y_train_enc)\n",
    "\n",
    "# LogisticRegression\n",
    "lgr_search = BayesSearchCV(\n",
    "    LogisticRegression(),\n",
    "    {\n",
    "        \"penalty\": (\"l2\",),\n",
    "        \"C\": (0.01, 1.1, \"log-uniform\"),\n",
    "    },\n",
    "    n_iter=10,\n",
    "    scoring=\"f1\",\n",
    "    verbose=4,\n",
    "    cv=3,\n",
    "    n_points=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "%time lgr_search.fit(X_train, y_train_enc, sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.865\n",
      "Precision: 0.863\n",
      "Recall: 0.864\n",
      "F1 Score: 0.863\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "model_eval(y_test_enc, lgr_search.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Write model to pickle file\n",
    "pickle.dump(\n",
    "    lgr_search.best_estimator_,\n",
    "    Path(\"../data/models/baseline/logistic_binary.pkl\").open(\"wb\"),\n",
    ")\n",
    "\n",
    "# Label Encoder to pickle file\n",
    "pickle.dump(\n",
    "    le,\n",
    "    Path(\"../data/models/baseline/logistic_binary_label_encoder.pkl\").open(\"wb\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END eta=0.025534761227908934, gamma=1, max_depth=11, min_child_weight=7;, score=0.853 total time=  18.3s\n",
      "[CV 2/3] END eta=0.025534761227908934, gamma=1, max_depth=11, min_child_weight=7;, score=0.849 total time=  12.6s\n",
      "[CV 3/3] END eta=0.025534761227908934, gamma=1, max_depth=11, min_child_weight=7;, score=0.841 total time=  13.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END eta=0.14968195367854237, gamma=0, max_depth=22, min_child_weight=7;, score=0.863 total time=  11.7s\n",
      "[CV 2/3] END eta=0.14968195367854237, gamma=0, max_depth=22, min_child_weight=7;, score=0.861 total time=  11.5s\n",
      "[CV 3/3] END eta=0.14968195367854237, gamma=0, max_depth=22, min_child_weight=7;, score=0.854 total time=  11.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END eta=0.04004897299285126, gamma=1, max_depth=14, min_child_weight=6;, score=0.856 total time=  17.1s\n",
      "[CV 2/3] END eta=0.04004897299285126, gamma=1, max_depth=14, min_child_weight=6;, score=0.851 total time=  16.9s\n",
      "[CV 3/3] END eta=0.04004897299285126, gamma=1, max_depth=14, min_child_weight=6;, score=0.844 total time=  17.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END eta=0.03158742137487921, gamma=1, max_depth=18, min_child_weight=10;, score=0.853 total time=  14.8s\n",
      "[CV 2/3] END eta=0.03158742137487921, gamma=1, max_depth=18, min_child_weight=10;, score=0.851 total time=  15.1s\n",
      "[CV 3/3] END eta=0.03158742137487921, gamma=1, max_depth=18, min_child_weight=10;, score=0.844 total time=  14.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END eta=0.01715609891068854, gamma=1, max_depth=12, min_child_weight=8;, score=0.848 total time=  15.0s\n",
      "[CV 2/3] END eta=0.01715609891068854, gamma=1, max_depth=12, min_child_weight=8;, score=0.845 total time=  14.9s\n",
      "[CV 3/3] END eta=0.01715609891068854, gamma=1, max_depth=12, min_child_weight=8;, score=0.838 total time=  15.0s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END eta=0.4160002322918169, gamma=1, max_depth=5, min_child_weight=4;, score=0.853 total time=   2.5s\n",
      "[CV 2/3] END eta=0.4160002322918169, gamma=1, max_depth=5, min_child_weight=4;, score=0.853 total time=   2.5s\n",
      "[CV 3/3] END eta=0.4160002322918169, gamma=1, max_depth=5, min_child_weight=4;, score=0.846 total time=   2.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END eta=0.3768564285864545, gamma=0, max_depth=14, min_child_weight=8;, score=0.861 total time=   7.2s\n",
      "[CV 2/3] END eta=0.3768564285864545, gamma=0, max_depth=14, min_child_weight=8;, score=0.861 total time=   7.1s\n",
      "[CV 3/3] END eta=0.3768564285864545, gamma=0, max_depth=14, min_child_weight=8;, score=0.857 total time=   7.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END eta=0.0927772873738461, gamma=0, max_depth=22, min_child_weight=10;, score=0.861 total time=  11.9s\n",
      "[CV 2/3] END eta=0.0927772873738461, gamma=0, max_depth=22, min_child_weight=10;, score=0.862 total time=  11.9s\n",
      "[CV 3/3] END eta=0.0927772873738461, gamma=0, max_depth=22, min_child_weight=10;, score=0.853 total time=  11.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END eta=0.6509687279153527, gamma=0, max_depth=13, min_child_weight=8;, score=0.859 total time=   6.1s\n",
      "[CV 2/3] END eta=0.6509687279153527, gamma=0, max_depth=13, min_child_weight=8;, score=0.854 total time=   6.0s\n",
      "[CV 3/3] END eta=0.6509687279153527, gamma=0, max_depth=13, min_child_weight=8;, score=0.851 total time=   5.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END eta=0.03279800265484636, gamma=1, max_depth=14, min_child_weight=6;, score=0.853 total time=  17.9s\n",
      "[CV 2/3] END eta=0.03279800265484636, gamma=1, max_depth=14, min_child_weight=6;, score=0.851 total time=  17.8s\n",
      "[CV 3/3] END eta=0.03279800265484636, gamma=1, max_depth=14, min_child_weight=6;, score=0.843 total time=  18.2s\n",
      "CPU times: user 8min 31s, sys: 9.86 s, total: 8min 40s\n",
      "Wall time: 6min 7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=3,\n",
       "              estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                      callbacks=None, colsample_bylevel=None,\n",
       "                                      colsample_bynode=None,\n",
       "                                      colsample_bytree=None,\n",
       "                                      early_stopping_rounds=None,\n",
       "                                      enable_categorical=False,\n",
       "                                      eval_metric=None, feature_types=None,\n",
       "                                      gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                      importance_type=None,\n",
       "                                      interaction_constraints=None,\n",
       "                                      learning_rate=None...\n",
       "                                      max_delta_step=None, max_depth=None,\n",
       "                                      max_leaves=None, min_child_weight=None,\n",
       "                                      missing=nan, monotone_constraints=None,\n",
       "                                      n_estimators=100, n_jobs=None,\n",
       "                                      num_parallel_tree=None, predictor=None,\n",
       "                                      random_state=None, ...),\n",
       "              n_iter=10, scoring=&#x27;f1&#x27;,\n",
       "              search_spaces={&#x27;eta&#x27;: (0.01, 1.0, &#x27;log-uniform&#x27;),\n",
       "                             &#x27;gamma&#x27;: (0, 1, &#x27;uniform&#x27;),\n",
       "                             &#x27;max_depth&#x27;: (1, 30, &#x27;uniform&#x27;),\n",
       "                             &#x27;min_child_weight&#x27;: (1, 10, &#x27;uniform&#x27;)},\n",
       "              verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesSearchCV</label><div class=\"sk-toggleable__content\"><pre>BayesSearchCV(cv=3,\n",
       "              estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                      callbacks=None, colsample_bylevel=None,\n",
       "                                      colsample_bynode=None,\n",
       "                                      colsample_bytree=None,\n",
       "                                      early_stopping_rounds=None,\n",
       "                                      enable_categorical=False,\n",
       "                                      eval_metric=None, feature_types=None,\n",
       "                                      gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                      importance_type=None,\n",
       "                                      interaction_constraints=None,\n",
       "                                      learning_rate=None...\n",
       "                                      max_delta_step=None, max_depth=None,\n",
       "                                      max_leaves=None, min_child_weight=None,\n",
       "                                      missing=nan, monotone_constraints=None,\n",
       "                                      n_estimators=100, n_jobs=None,\n",
       "                                      num_parallel_tree=None, predictor=None,\n",
       "                                      random_state=None, ...),\n",
       "              n_iter=10, scoring=&#x27;f1&#x27;,\n",
       "              search_spaces={&#x27;eta&#x27;: (0.01, 1.0, &#x27;log-uniform&#x27;),\n",
       "                             &#x27;gamma&#x27;: (0, 1, &#x27;uniform&#x27;),\n",
       "                             &#x27;max_depth&#x27;: (1, 30, &#x27;uniform&#x27;),\n",
       "                             &#x27;min_child_weight&#x27;: (1, 10, &#x27;uniform&#x27;)},\n",
       "              verbose=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                      callbacks=None, colsample_bylevel=None,\n",
       "                                      colsample_bynode=None,\n",
       "                                      colsample_bytree=None,\n",
       "                                      early_stopping_rounds=None,\n",
       "                                      enable_categorical=False,\n",
       "                                      eval_metric=None, feature_types=None,\n",
       "                                      gamma=None, gpu_id=None, grow_policy=None,\n",
       "                                      importance_type=None,\n",
       "                                      interaction_constraints=None,\n",
       "                                      learning_rate=None...\n",
       "                                      max_delta_step=None, max_depth=None,\n",
       "                                      max_leaves=None, min_child_weight=None,\n",
       "                                      missing=nan, monotone_constraints=None,\n",
       "                                      n_estimators=100, n_jobs=None,\n",
       "                                      num_parallel_tree=None, predictor=None,\n",
       "                                      random_state=None, ...),\n",
       "              n_iter=10, scoring='f1',\n",
       "              search_spaces={'eta': (0.01, 1.0, 'log-uniform'),\n",
       "                             'gamma': (0, 1, 'uniform'),\n",
       "                             'max_depth': (1, 30, 'uniform'),\n",
       "                             'min_child_weight': (1, 10, 'uniform')},\n",
       "              verbose=4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "weights = class_weight.compute_sample_weight(class_weight=\"balanced\", y=y_train_enc)\n",
    "\n",
    "# XGBoost model\n",
    "xgb_search = BayesSearchCV(\n",
    "    XGBClassifier(tree_method=\"gpu_hist\"),\n",
    "    {\n",
    "        \"eta\": (0.01, 1.0, \"log-uniform\"),\n",
    "        \"max_depth\": (1, 30, \"uniform\"),\n",
    "        \"gamma\": (0, 1, \"uniform\"),\n",
    "        \"min_child_weight\": (1, 10, \"uniform\"),\n",
    "    },\n",
    "    n_iter=10,\n",
    "    scoring=\"f1\",\n",
    "    verbose=4,\n",
    "    cv=3,\n",
    "    n_points=1,\n",
    "    n_jobs=1,\n",
    ")\n",
    "%time xgb_search.fit(X_train, y_train_enc, sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.884\n",
      "Precision: 0.884\n",
      "Recall: 0.88\n",
      "F1 Score: 0.881\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "model_eval(y_test_enc, xgb_search.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
