{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- track_stem: string (nullable = true)\n",
      " |-- start_time: long (nullable = true)\n",
      " |-- metadata_species: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- predicted_species: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- predicted_species_prob: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- embedding: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- next_embedding: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- track_embedding: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- primary_label: string (nullable = true)\n",
      " |-- species: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- species_count: long (nullable = false)\n",
      "\n",
      "+----------+----------+----------------+--------------------+----------------------+--------------------+--------------------+--------------------+-------------+--------------------+-------------+\n",
      "|track_stem|start_time|metadata_species|   predicted_species|predicted_species_prob|           embedding|      next_embedding|     track_embedding|primary_label|             species|species_count|\n",
      "+----------+----------+----------------+--------------------+----------------------+--------------------+--------------------+--------------------+-------------+--------------------+-------------+\n",
      "|  XC125862|        40|       [abythr1]|  [abythr1, wbrcha2]|  [0.72823923447200...|[1.4855427, 0.454...|[0.9370399, 0.233...|[1.0989836, 0.511...|      abythr1|[abythr1, abythr1...|          142|\n",
      "|  XC227239|        50|       [abythr1]|[combul2, grbcam1...|  [0.84211377519815...|[1.6610856, 0.870...|[1.4390839, 1.616...|[1.5228174, 1.202...|      abythr1|[abythr1, combul2...|          142|\n",
      "|  XC509507|        20|       [abythr1]|           [fotdro5]|  [0.6930028164341019]|[0.9759565, 0.753...|[1.0162606, 1.178...|[0.99444264, 1.14...|      abythr1|  [abythr1, fotdro5]|          142|\n",
      "|  XC620997|        10|       [abythr1]|[abythr1, abythr1...|  [0.96802423963072...|[1.5794071, 0.886...|[1.0814278, 0.572...|[1.3417553, 0.759...|      abythr1|[abythr1, abythr1...|          142|\n",
      "|  XC125862|        50|       [abythr1]|           [abythr1]|  [0.8696589410631123]|[0.9370399, 0.233...|[0.9370399, 0.233...|[1.0989836, 0.511...|      abythr1|  [abythr1, abythr1]|          142|\n",
      "+----------+----------+----------------+--------------------+----------------------+--------------------+--------------------+--------------------+-------------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from birdclef.utils import get_spark\n",
    "from pyspark.sql import Window, functions as F\n",
    "import os\n",
    "\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"../data/tmp/spark\"\n",
    "\n",
    "spark = get_spark(memory=\"5g\")\n",
    "df = spark.read.parquet(\"../data/processed/birdclef-2023/train_postprocessed/v3\")\n",
    "df = (\n",
    "    df.withColumn(\"primary_label\", F.col(\"metadata_species\")[0])\n",
    "    .withColumn(\"species\", F.concat(\"metadata_species\", \"predicted_species\"))\n",
    "    .withColumn(\"species_count\", F.count(\"*\").over(Window.partitionBy(\"primary_label\")))\n",
    ")\n",
    "# df = df.where(\"species_count > 1\")\n",
    "df.printSchema()\n",
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "def model_eval(truth, preds):\n",
    "    print(\"Accuracy:\", accuracy_score(truth, preds))\n",
    "    print(\n",
    "        \"Precision:\",\n",
    "        precision_score(truth, preds, average=\"macro\"),\n",
    "    )\n",
    "    print(\n",
    "        \"Recall:\",\n",
    "        recall_score(truth, preds, average=\"macro\"),\n",
    "    )\n",
    "    print(\n",
    "        \"F1 Score:\",\n",
    "        f1_score(truth, preds, average=\"macro\"),\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "current and next token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+--------------------+\n",
      "|   predicted_species|primary_label|           embedding|      next_embedding|\n",
      "+--------------------+-------------+--------------------+--------------------+\n",
      "|  [abythr1, wbrcha2]|      abythr1|[1.4855427, 0.454...|[0.9370399, 0.233...|\n",
      "|[combul2, grbcam1...|      abythr1|[1.6610856, 0.870...|[1.4390839, 1.616...|\n",
      "|           [fotdro5]|      abythr1|[0.9759565, 0.753...|[1.0162606, 1.178...|\n",
      "|[abythr1, abythr1...|      abythr1|[1.5794071, 0.886...|[1.0814278, 0.572...|\n",
      "|           [abythr1]|      abythr1|[0.9370399, 0.233...|[0.9370399, 0.233...|\n",
      "+--------------------+-------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed = df.select(\"predicted_species\", \"primary_label\", \"embedding\", \"next_embedding\")\n",
    "parsed.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_species</th>\n",
       "      <th>primary_label</th>\n",
       "      <th>embedding</th>\n",
       "      <th>next_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[abythr1, wbrcha2]</td>\n",
       "      <td>abythr1</td>\n",
       "      <td>[1.4855427, 0.4541664, 1.0472355, 1.3523579, 1...</td>\n",
       "      <td>[0.9370399, 0.2331794, 0.5724607, 1.3511919, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[combul2, grbcam1, combuz1]</td>\n",
       "      <td>abythr1</td>\n",
       "      <td>[1.6610856, 0.87099504, 0.29712436, 0.7613897,...</td>\n",
       "      <td>[1.4390839, 1.6169457, 1.8661345, 0.8268714, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fotdro5]</td>\n",
       "      <td>abythr1</td>\n",
       "      <td>[0.9759565, 0.75392014, 0.6601531, 0.51182395,...</td>\n",
       "      <td>[1.0162606, 1.1786319, 0.6472011, 0.5133413, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[abythr1, abythr1, thrnig1, thrnig1]</td>\n",
       "      <td>abythr1</td>\n",
       "      <td>[1.5794071, 0.8864207, 1.2426404, 1.2989092, 0...</td>\n",
       "      <td>[1.0814278, 0.5720312, 1.1402651, 1.4965066, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[abythr1]</td>\n",
       "      <td>abythr1</td>\n",
       "      <td>[0.9370399, 0.2331794, 0.5724607, 1.3511919, 0...</td>\n",
       "      <td>[0.9370399, 0.2331794, 0.5724607, 1.3511919, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      predicted_species primary_label  \\\n",
       "0                    [abythr1, wbrcha2]       abythr1   \n",
       "1           [combul2, grbcam1, combuz1]       abythr1   \n",
       "2                             [fotdro5]       abythr1   \n",
       "3  [abythr1, abythr1, thrnig1, thrnig1]       abythr1   \n",
       "4                             [abythr1]       abythr1   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [1.4855427, 0.4541664, 1.0472355, 1.3523579, 1...   \n",
       "1  [1.6610856, 0.87099504, 0.29712436, 0.7613897,...   \n",
       "2  [0.9759565, 0.75392014, 0.6601531, 0.51182395,...   \n",
       "3  [1.5794071, 0.8864207, 1.2426404, 1.2989092, 0...   \n",
       "4  [0.9370399, 0.2331794, 0.5724607, 1.3511919, 0...   \n",
       "\n",
       "                                      next_embedding  \n",
       "0  [0.9370399, 0.2331794, 0.5724607, 1.3511919, 0...  \n",
       "1  [1.4390839, 1.6169457, 1.8661345, 0.8268714, 1...  \n",
       "2  [1.0162606, 1.1786319, 0.6472011, 0.5133413, 0...  \n",
       "3  [1.0814278, 0.5720312, 1.1402651, 1.4965066, 0...  \n",
       "4  [0.9370399, 0.2331794, 0.5724607, 1.3511919, 0...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = parsed.toPandas()\n",
    "data.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "# labels = mlb.fit_transform(data[\"predicted_species\"])\n",
    "# print(labels.shape)\n",
    "\n",
    "# embeddings = np.stack(data[\"embedding\"])\n",
    "# next_emb = np.stack(data[\"next_embedding\"])\n",
    "# print(embeddings.shape, next_emb.shape)\n",
    "# emb = np.concatenate((embeddings, next_emb), axis=1)\n",
    "# print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_x_y(data):\n",
    "    x = np.concatenate(\n",
    "        (np.stack(data.embedding), np.stack(data.next_embedding)), axis=1\n",
    "    )\n",
    "    y = mlb.transform(data.predicted_species)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 predicted_species primary_label  \\\n",
      "56324                  [klacuc1, klacuc1, afecuc1]       didcuc1   \n",
      "48523                  [carcha1, carcha1, carcha1]       carcha1   \n",
      "43264             [comsan, comsan, comsan, comsan]        comsan   \n",
      "53116                                    [colsun2]       cibwar1   \n",
      "56325  [meypar1, meypar1, wlwwar, blbpuf2, wlwwar]       meypar1   \n",
      "\n",
      "                                               embedding  \\\n",
      "56324  [0.9282538, 0.85244304, 0.64371747, 0.9679206,...   \n",
      "48523  [1.2264075, 0.91729265, 0.659605, 0.4417752, 1...   \n",
      "43264  [1.7824721, 1.4432603, 0.51925224, 0.6429393, ...   \n",
      "53116  [0.76846176, 0.91573334, 0.8185377, 1.0414224,...   \n",
      "56325  [2.4270287, 1.4127231, 1.0112065, 0.6295299, 0...   \n",
      "\n",
      "                                          next_embedding  \\\n",
      "56324  [0.73853236, 1.1838487, 1.358802, 0.8135739, 0...   \n",
      "48523  [1.1825973, 1.2704992, 0.3688372, 1.012795, 0....   \n",
      "43264  [1.2682344, 1.4572191, 0.32428205, 0.97598964,...   \n",
      "53116  [0.87304425, 0.96519345, 0.8420605, 0.43375358...   \n",
      "56325  [0.8885708, 1.1449395, 0.8657527, 0.39204642, ...   \n",
      "\n",
      "                                         track_embedding  \n",
      "56324  [0.76945335, 0.95157564, 0.7929162, 0.80579096...  \n",
      "48523  [0.9303654, 1.0030951, 0.6425495, 0.95856875, ...  \n",
      "43264  [1.198627, 1.2510281, 0.66858846, 0.71105814, ...  \n",
      "53116  [1.1379017, 0.87895405, 0.6080421, 0.720059, 1...  \n",
      "56325  [1.6577997, 1.2788312, 0.9384796, 0.51078814, ...  \n",
      "(61450,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, stratify=data.primary_label)\n",
    "\n",
    "print(train.head(5))\n",
    "\n",
    "weights = compute_sample_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    y=train.primary_label,\n",
    ")\n",
    "print(weights.shape)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(data.predicted_species)\n",
    "train_x, train_y = split_x_y(train)\n",
    "test_x, test_y = split_x_y(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2870823430728366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6341810776088794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.20198595718608378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.2917415148921085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48481025107652603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(tree_method=\"gpu_hist\")\n",
    "clf.fit(train_x, train_y, verbose=True)\n",
    "preds = clf.predict(test_x)\n",
    "model_eval(test_y, preds)\n",
    "print(average_precision_score(test_y, clf.predict_proba(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = BayesSearchCV(\n",
    "    XGBClassifier(tree_method=\"gpu_hist\"),\n",
    "    {\n",
    "        \"max_depth\": (3, 15, \"uniform\"),\n",
    "        \"gamma\": (0.0, 1.0, \"uniform\"),\n",
    "        \"min_child_weight\": (1, 10, \"uniform\"),\n",
    "    },\n",
    "    fit_params={\"sample_weight\": weights},\n",
    "    n_iter=8,\n",
    "    scoring=\"f1_macro\",\n",
    "    verbose=4,\n",
    "    cv=2,\n",
    "    n_points=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "search.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_stem</th>\n",
       "      <th>start_time</th>\n",
       "      <th>metadata_species</th>\n",
       "      <th>predicted_species</th>\n",
       "      <th>predicted_species_prob</th>\n",
       "      <th>embedding</th>\n",
       "      <th>next_embedding</th>\n",
       "      <th>track_embedding</th>\n",
       "      <th>primary_label</th>\n",
       "      <th>species</th>\n",
       "      <th>species_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XC125862</td>\n",
       "      <td>40</td>\n",
       "      <td>[abythr1]</td>\n",
       "      <td>[abythr1, wbrcha2]</td>\n",
       "      <td>[0.7282392344720093, 0.5216352416664949]</td>\n",
       "      <td>[1.4855427, 0.4541664, 1.0472355, 1.3523579, 1...</td>\n",
       "      <td>[0.9370399, 0.2331794, 0.5724607, 1.3511919, 0...</td>\n",
       "      <td>[1.0989836, 0.511663, 0.79813445, 1.251782, 0....</td>\n",
       "      <td>abythr1</td>\n",
       "      <td>[abythr1, abythr1, wbrcha2]</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XC227239</td>\n",
       "      <td>50</td>\n",
       "      <td>[abythr1]</td>\n",
       "      <td>[combul2, grbcam1, combuz1]</td>\n",
       "      <td>[0.8421137751981587, 0.8241570000064344, 0.754...</td>\n",
       "      <td>[1.6610856, 0.87099504, 0.29712436, 0.7613897,...</td>\n",
       "      <td>[1.4390839, 1.6169457, 1.8661345, 0.8268714, 1...</td>\n",
       "      <td>[1.5228174, 1.2024852, 0.9217374, 0.66376007, ...</td>\n",
       "      <td>abythr1</td>\n",
       "      <td>[abythr1, combul2, grbcam1, combuz1]</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XC509507</td>\n",
       "      <td>20</td>\n",
       "      <td>[abythr1]</td>\n",
       "      <td>[fotdro5]</td>\n",
       "      <td>[0.6930028164341019]</td>\n",
       "      <td>[0.9759565, 0.75392014, 0.6601531, 0.51182395,...</td>\n",
       "      <td>[1.0162606, 1.1786319, 0.6472011, 0.5133413, 0...</td>\n",
       "      <td>[0.99444264, 1.1462014, 0.775025, 0.4755587, 1...</td>\n",
       "      <td>abythr1</td>\n",
       "      <td>[abythr1, fotdro5]</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XC620997</td>\n",
       "      <td>10</td>\n",
       "      <td>[abythr1]</td>\n",
       "      <td>[abythr1, abythr1, thrnig1, thrnig1]</td>\n",
       "      <td>[0.9680242396307245, 0.8786584090490244, 0.553...</td>\n",
       "      <td>[1.5794071, 0.8864207, 1.2426404, 1.2989092, 0...</td>\n",
       "      <td>[1.0814278, 0.5720312, 1.1402651, 1.4965066, 0...</td>\n",
       "      <td>[1.3417553, 0.7599494, 1.1932622, 0.980361, 0....</td>\n",
       "      <td>abythr1</td>\n",
       "      <td>[abythr1, abythr1, abythr1, thrnig1, thrnig1]</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XC125862</td>\n",
       "      <td>50</td>\n",
       "      <td>[abythr1]</td>\n",
       "      <td>[abythr1]</td>\n",
       "      <td>[0.8696589410631123]</td>\n",
       "      <td>[0.9370399, 0.2331794, 0.5724607, 1.3511919, 0...</td>\n",
       "      <td>[0.9370399, 0.2331794, 0.5724607, 1.3511919, 0...</td>\n",
       "      <td>[1.0989836, 0.511663, 0.79813445, 1.251782, 0....</td>\n",
       "      <td>abythr1</td>\n",
       "      <td>[abythr1, abythr1]</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  track_stem  start_time metadata_species  \\\n",
       "0   XC125862          40        [abythr1]   \n",
       "1   XC227239          50        [abythr1]   \n",
       "2   XC509507          20        [abythr1]   \n",
       "3   XC620997          10        [abythr1]   \n",
       "4   XC125862          50        [abythr1]   \n",
       "\n",
       "                      predicted_species  \\\n",
       "0                    [abythr1, wbrcha2]   \n",
       "1           [combul2, grbcam1, combuz1]   \n",
       "2                             [fotdro5]   \n",
       "3  [abythr1, abythr1, thrnig1, thrnig1]   \n",
       "4                             [abythr1]   \n",
       "\n",
       "                              predicted_species_prob  \\\n",
       "0           [0.7282392344720093, 0.5216352416664949]   \n",
       "1  [0.8421137751981587, 0.8241570000064344, 0.754...   \n",
       "2                               [0.6930028164341019]   \n",
       "3  [0.9680242396307245, 0.8786584090490244, 0.553...   \n",
       "4                               [0.8696589410631123]   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [1.4855427, 0.4541664, 1.0472355, 1.3523579, 1...   \n",
       "1  [1.6610856, 0.87099504, 0.29712436, 0.7613897,...   \n",
       "2  [0.9759565, 0.75392014, 0.6601531, 0.51182395,...   \n",
       "3  [1.5794071, 0.8864207, 1.2426404, 1.2989092, 0...   \n",
       "4  [0.9370399, 0.2331794, 0.5724607, 1.3511919, 0...   \n",
       "\n",
       "                                      next_embedding  \\\n",
       "0  [0.9370399, 0.2331794, 0.5724607, 1.3511919, 0...   \n",
       "1  [1.4390839, 1.6169457, 1.8661345, 0.8268714, 1...   \n",
       "2  [1.0162606, 1.1786319, 0.6472011, 0.5133413, 0...   \n",
       "3  [1.0814278, 0.5720312, 1.1402651, 1.4965066, 0...   \n",
       "4  [0.9370399, 0.2331794, 0.5724607, 1.3511919, 0...   \n",
       "\n",
       "                                     track_embedding primary_label  \\\n",
       "0  [1.0989836, 0.511663, 0.79813445, 1.251782, 0....       abythr1   \n",
       "1  [1.5228174, 1.2024852, 0.9217374, 0.66376007, ...       abythr1   \n",
       "2  [0.99444264, 1.1462014, 0.775025, 0.4755587, 1...       abythr1   \n",
       "3  [1.3417553, 0.7599494, 1.1932622, 0.980361, 0....       abythr1   \n",
       "4  [1.0989836, 0.511663, 0.79813445, 1.251782, 0....       abythr1   \n",
       "\n",
       "                                         species  species_count  \n",
       "0                    [abythr1, abythr1, wbrcha2]            142  \n",
       "1           [abythr1, combul2, grbcam1, combuz1]            142  \n",
       "2                             [abythr1, fotdro5]            142  \n",
       "3  [abythr1, abythr1, abythr1, thrnig1, thrnig1]            142  \n",
       "4                             [abythr1, abythr1]            142  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parsed = df.select(\n",
    "#     \"predicted_species\",\n",
    "#     \"primary_label\",\n",
    "#     \"embedding\",\n",
    "#     \"next_embedding\",\n",
    "#     \"track_embedding\",\n",
    "# )\n",
    "# parsed.show(n=5)\n",
    "data = df.toPandas()\n",
    "data.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      track_stem  start_time metadata_species  \\\n",
      "20816   XC471862          60         [hoopoe]   \n",
      "47602   XC399994          80        [bswdov1]   \n",
      "60128   XC675673          30        [eaywag1]   \n",
      "60359   XC334142           0        [eaywag1]   \n",
      "40963   XC322373          10         [yefcan]   \n",
      "\n",
      "                        predicted_species  \\\n",
      "20816                            [hoopoe]   \n",
      "47602                  [bswdov1, bswdov1]   \n",
      "60128         [eaywag1, eaywag1, eaywag1]   \n",
      "60359                            [barswa]   \n",
      "40963  [yefcan, eaywag1, yefcan, eaywag1]   \n",
      "\n",
      "                                  predicted_species_prob  \\\n",
      "20816                               [0.5947268731195006]   \n",
      "47602           [0.9891283636639615, 0.9747976973291222]   \n",
      "60128  [0.942331024526395, 0.9197274155762972, 0.5563...   \n",
      "60359                               [0.8097300783595898]   \n",
      "40963  [0.9109804922063218, 0.9103243629862736, 0.875...   \n",
      "\n",
      "                                               embedding  \\\n",
      "20816  [1.950202, 1.2247757, 0.91652423, 0.6978936, 1...   \n",
      "47602  [0.97912383, 1.7593756, 0.8786888, 1.5912037, ...   \n",
      "60128  [1.3772484, 1.8732147, 0.69525963, 0.24555115,...   \n",
      "60359  [1.1186291, 1.187116, 0.21964963, 0.8594466, 1...   \n",
      "40963  [1.9806328, 1.9400002, 0.56093925, 0.69422024,...   \n",
      "\n",
      "                                          next_embedding  \\\n",
      "20816  [1.950202, 1.2247757, 0.91652423, 0.6978936, 1...   \n",
      "47602  [0.49457595, 0.44284597, 0.30304405, 1.2959826...   \n",
      "60128  [2.3544004, 1.3286908, 1.3306504, 0.8222125, 1...   \n",
      "60359  [1.1196896, 1.4993654, 0.10713488, 0.6842992, ...   \n",
      "40963  [1.9806328, 1.9400002, 0.56093925, 0.69422024,...   \n",
      "\n",
      "                                         track_embedding primary_label  \\\n",
      "20816  [2.0322006, 1.5582819, 0.57990193, 0.91445076,...        hoopoe   \n",
      "47602  [0.9027336, 1.3541442, 0.63705015, 1.4340281, ...       bswdov1   \n",
      "60128  [1.4916891, 1.5176314, 1.0020537, 0.66908836, ...       eaywag1   \n",
      "60359  [1.0950625, 1.6888183, 0.32666576, 0.82831204,...       eaywag1   \n",
      "40963  [1.8051147, 1.5256546, 0.55770993, 0.8030189, ...        yefcan   \n",
      "\n",
      "                                          species  species_count  \n",
      "20816                            [hoopoe, hoopoe]           2600  \n",
      "47602                 [bswdov1, bswdov1, bswdov1]            128  \n",
      "60128        [eaywag1, eaywag1, eaywag1, eaywag1]           1773  \n",
      "60359                           [eaywag1, barswa]           1773  \n",
      "40963  [yefcan, yefcan, eaywag1, yefcan, eaywag1]            294  \n",
      "(61450,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "def split_x_y(data):\n",
    "    x = np.concatenate(\n",
    "        (\n",
    "            np.stack(data.embedding),\n",
    "            np.stack(data.next_embedding),\n",
    "            np.stack(data.track_embedding),\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    y = mlb.transform(data.predicted_species)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, stratify=data.primary_label)\n",
    "\n",
    "print(train.head(5))\n",
    "\n",
    "weights = compute_sample_weight(\n",
    "    class_weight=None,\n",
    "    y=train.primary_label,\n",
    ")\n",
    "print(weights.shape)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(data.species)\n",
    "train_x, train_y = split_x_y(train)\n",
    "test_x, test_y = split_x_y(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3048371312735915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6907287964057018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.3036790183529477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.40340066136931235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5434118400483244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nzhon\\Codes\\birdclef-2023\\.venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(tree_method=\"gpu_hist\")\n",
    "clf.fit(train_x, train_y, verbose=True)\n",
    "preds = clf.predict(test_x)\n",
    "model_eval(test_y, preds)\n",
    "print(average_precision_score(test_y, clf.predict_proba(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    }
   ],
   "source": [
    "search = BayesSearchCV(\n",
    "    XGBClassifier(tree_method=\"hist\"),\n",
    "    {\n",
    "        \"max_depth\": (3, 15, \"uniform\"),\n",
    "        \"gamma\": (0.0, 1.0, \"uniform\"),\n",
    "        \"min_child_weight\": (1, 10, \"uniform\"),\n",
    "    },\n",
    "    fit_params={\"sample_weight\": weights},\n",
    "    n_iter=10,\n",
    "    scoring=\"f1_macro\",\n",
    "    verbose=4,\n",
    "    cv=2,\n",
    "    n_points=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "search.fit(train_x, train_y)\n",
    "model_eval(test_y, search.predict(test_x))\n",
    "print(average_precision_score(test_y, search.predict_proba(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
